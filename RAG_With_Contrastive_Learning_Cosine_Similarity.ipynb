{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "400cc4310e6d4f988fc0f9d935399c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_186f9ea36c944c478317245d56cea06a",
              "IPY_MODEL_22c4d06835df40158fc65289ff04085d",
              "IPY_MODEL_b3dc18e401f84c7591c9f991b16e4a17"
            ],
            "layout": "IPY_MODEL_90471e1b6a084f539817d369e6b8db06"
          }
        },
        "186f9ea36c944c478317245d56cea06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72619f3c67749d09fee1b476119c7a1",
            "placeholder": "​",
            "style": "IPY_MODEL_09916226602e4001833b0c8603699c63",
            "value": "100%"
          }
        },
        "22c4d06835df40158fc65289ff04085d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4092479eff4b80a96a693167cbd213",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f4657f534dd4c62aed2f65af6003c11",
            "value": 1
          }
        },
        "b3dc18e401f84c7591c9f991b16e4a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca2f304701cf4f689553295634cd7e3c",
            "placeholder": "​",
            "style": "IPY_MODEL_447f50d4fdba4925af8363e7e08a1ec6",
            "value": " 1/1 [00:00&lt;00:00, 18.50it/s]"
          }
        },
        "90471e1b6a084f539817d369e6b8db06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72619f3c67749d09fee1b476119c7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09916226602e4001833b0c8603699c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e4092479eff4b80a96a693167cbd213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f4657f534dd4c62aed2f65af6003c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca2f304701cf4f689553295634cd7e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447f50d4fdba4925af8363e7e08a1ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znXR8ulWHJc8",
        "outputId": "b6dd542f-6886-44ad-cd95-606c58c19afb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "C05dbNGBoemg",
        "outputId": "1d9d630e-33bf-4a3d-b5f2-d08153eb1591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer,T5ForConditionalGeneration,Adafactor"
      ],
      "metadata": {
        "id": "I38M4y6Uo1-T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n"
      ],
      "metadata": {
        "id": "HmfokWZ4ozIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db17310a-cf5c-4e2c-f97b-bad9a66a3360"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t5_tokenizer)"
      ],
      "metadata": {
        "id": "Lsg93lnnpEZe",
        "outputId": "81913e5f-57af-4261-f367-307eb71e06a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5Tokenizer(name_or_path='t5-base', vocab_size=32100, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "id": "c55Qd_YxpL20"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WRcCW8olSDOF"
      },
      "outputs": [],
      "source": [
        "titles = []\n",
        "articles = []\n",
        "\n",
        "pdf_directory = \"/content/sample_data/research\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "import os\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh5aAjAyPNQh",
        "outputId": "ac75da15-eb60-42bb-9642-cf203f934afa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_data = []\n",
        "\n",
        "# Iterate through the files in the folder\n",
        "# Iterate through the files in the folder\n",
        "# Iterate over each file in the directory\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    # Check if the file is a PDF\n",
        "    if filename.endswith('.pdf'):\n",
        "        # Construct the full path of the PDF file\n",
        "        pdf_path = os.path.join(pdf_directory, filename)\n",
        "\n",
        "        # Open the PDF file and create a PdfReader object\n",
        "        with open(pdf_path, 'rb') as pdf_file:\n",
        "            pdf_reader = PdfReader(pdf_file)\n",
        "            article_name = os.path.splitext(filename)[0]\n",
        "            # Initialize an empty string to store the extracted text\n",
        "            extracted_text = \"\"\n",
        "\n",
        "            # Iterate through each page of the PDF\n",
        "            for page in pdf_reader.pages:\n",
        "                # Extract text from the page\n",
        "                text = page.extract_text()\n",
        "                # Append the extracted text to the overall text\n",
        "                extracted_text += text\n",
        "            \n",
        "            articles.append(extracted_text)\n",
        "            titles.append(article_name)\n"
      ],
      "metadata": {
        "id": "2VbIo69gZG_B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6oMMYX9P-2m",
        "outputId": "f5f36e87-ddbd-46e2-8b81-360ddf9722c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Human Papillomavirus Vaccination for Adults Updated Recommendations of the Advisory Committee on Immunization Practices',\n",
              " 'Use of a 2-Dose Schedule for Human Papillomavirus Vaccination — Updated Recommendations of the Advisory Committee on Immunization Practices',\n",
              " 'Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease',\n",
              " 'Recommendations of the Advisory Committee on Immunization Practices']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "0FLqHZleQBNO",
        "outputId": "f2404cfb-140c-4fc1-bf22-6b33a009bcf3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Morbidity and Mortality Weekly ReportMMWR  / December 16, 2016  / V ol. 65  /  No. 49  1405\\nUS Department of Health and Human Services/Centers for Disease Control and PreventionIntroduction\\nVaccination against human papillomavirus (HPV) is rec -\\nommended to prevent HPV infections and HPV-associated \\ndiseases, including cancers. Routine vaccination at age 11 or \\n12 years has been recommended by the Advisory Committee \\non Immunization Practices (ACIP) since 2006 for females and since 2011 for males ( 1,2). This report provides recom -\\nmendations and guidance regarding use of HPV vaccines and updates ACIP HPV vaccination recommendations previously published in 2014 and 2015 ( 1,2). This report includes new \\nrecommendations for use of a 2-dose schedule for girls and boys who initiate the vaccination series at ages 9 through 14 years. Three doses remain recommended for persons who initiate the vaccination series at ages 15 through 26 years and for immunocompromised persons.\\nBackground\\nHPV infection causes cervical, vaginal, and vulvar cancers \\nin women; penile cancers in men; and oropharyngeal and anal cancers as well as genital warts in both men and women ( 3). Three HPV vaccines are licensed for use in the United States. All are noninfectious. Quadrivalent and 9-valent HPV vac -\\ncines (4vHPV and 9vHPV, Gardasil and Gardasil 9, Merck and Co, Inc., Whitehouse Station, New Jersey) are licensed for use in females and males aged 9 through 26 years ( 1). Bivalent \\nHPV vaccine (2vHPV, Cervarix, GlaxoSmithKline, Rixensart, Belgium) is licensed for use in females aged 9 through 25 years (1). As of late 2016, only 9vHPV is being distributed in the \\nUnited States. The majority of all HPV-associated cancers are caused by HPV 16 or 18, types targeted by all three vaccines. In addition, 4vHPV targets HPV 6 and 11, types that cause \\ngenital warts. 9vHPV protects against these and five additional \\ntypes: HPV 31, 33, 45, 52, and 58. All three vaccines have been approved for administration in a 3-dose series at intervals of 0, 1 or 2, and 6 months. In October 2016, after considering new clinical trial results ( 4), the Food and Drug Administration \\n(FDA) also approved 9vHPV for use in a 2-dose series for girls and boys aged 9 through 14 years ( 5). In October 2016, \\nACIP recommended a 2-dose schedule for adolescents initiat -\\ning HPV vaccination in this age range. This report provides recommendations for use of 2-dose and 3-dose schedules for HPV vaccination.\\nMethods\\nDuring November 2015–October 2016, the ACIP HPV \\nVaccines Work Group held monthly telephone conferences to 1) review and evaluate the quality of the evidence assessing \\nimmunogenicity, efficacy, and postlicensure effectiveness of a \\n2-dose schedule; 2) consider benefits and harms of a 2-dose schedule; 3) weigh the variability in the values and preferences of patients and providers for a 2-dose schedule; and 4) examine health economic analyses. During teleconferences, summaries of findings were presented for Work Group discussion.\\nA systematic review was conducted to identify studies \\ninvolving human subjects* that reported primary data on any important or critical health outcomes related to HPV vaccination\\n† after 2 doses of 9vHPV, 4vHPV, or 2vHPV, \\nadministered at an interval of 0 and ≥6 months (±4 weeks) to Use of a 2-Dose Schedule for Human Papillomavirus Vaccination — Updated \\nRecommendations of the Advisory Committee on Immunization Practices\\nElissa Meites, MD1; Allison Kempe, MD2,3; Lauri E. Markowitz, MD1\\nRecommendations for use of vaccines in children, adolescents and adults are developed by the Advisory Committee on Immunization Practices (ACIP). ACIP is chartered as \\na federal advisory committee to provide expert external \\nadvice and guidance to the Director of the Centers for Disease Control and Prevention (CDC) on use of vaccines and related agents for the control of vaccine-preventable diseases in the civilian population of the United States. Recommendations for use of vaccines in children \\nand adolescents are harmonized to the greatest extent \\npossible with recommendations made by the American Academy of Pediatrics (AAP), the American Academy of Family Physicians (AAFP), and the American College of Obstetricians and Gynecologists (ACOG). Recommendations \\nfor routine use of vaccines in adults are harmonized with \\nrecommendations of AAFP , ACOG, and the American College of Physicians (ACP). ACIP recommendations approved by the CDC Director become agency guidelines on the date published in the Morbidity and Mortality Weekly Report (MMWR). Additional information about \\nACIP is available at  https://www.cdc.gov/vaccines/acip .\\n* N o primary data on special populations or medical conditions, including \\nimmunocompromising conditions, were available for 2-dose intervals and age \\nranges specified.\\n† N o primary data on other important and critical outcomes, including genital warts, \\nprecancers, oropharyngeal cancer, anal cancer, cervical cancer, vaginal/vulvar cancer, and penile cancer, were available for 2-dose intervals and age ranges specified.Morbidity and Mortality Weekly Report 1406  MMWR  /  December 16, 2016  /  V ol. 65  /  No. 49\\nUS Department of Health and Human Services/Centers for Disease Control and Preventionpersons aged 9 through 14 years. The review focused on this \\nage group given available 2-dose trial data for 9vHPV ( 4). \\nImmunogenicity outcomes of interest were seroconversion, \\ngeometric mean titers (GMTs), or antibody avidity. Studies \\nwere excluded if they lacked a comparison group in which efficacy of 3 doses of HPV vaccine against clinical endpoints was demonstrated in clinical trials (e.g., females aged 15 through 26 years).\\n§ Evidence regarding a 3-dose schedule for \\nHPV vaccine was reviewed previously (1,2).\\nQuality of evidence was evaluated using the Grading of \\nRecommendations Assessment, Development and Evaluation (GRADE) approach. Detailed methods and GRADE tables can be found online ( 6). Other studies from the search and \\nfrom the broader literature informed additional expert guid -\\nance that extended beyond the research question addressed formally via GRADE analysis ( 7). Evidence was reviewed by \\nthe Work Group, summarized, and publicly presented at the February and June 2016 ACIP meetings. CDC vaccine rec -\\nommendations are developed using the GRADE framework (8). Proposed recommendations were presented, and after a public comment period, were approved unanimously\\n¶ by the \\nvoting ACIP members at the October 2016 ACIP meeting.\\nSummary of Key Findings\\nImmunogenicity. In the 9vHPV clinical trial that was the \\nbasis for FDA approval of a 2-dose series, participants were girls and boys aged 9 through 14 years, compared with young \\nfemales aged 16 through 26 years ( 4). Among 1,377 partici -\\npants, ≥97.9% seroconverted to all nine vaccine-preventable \\nHPV types by 4 weeks after the last dose. For girls and boys who received 2 doses of 9vHPV 6 months apart (0, 6 month schedule) or 12 months apart (0, 12 month schedule), non -\\ninferiority criteria were met for seroconversion and GMTs. \\nFurthermore, GMTs were significantly higher for all 9vHPV \\ntypes among persons aged 9 through 14 years who received 2 doses compared with females aged 16–26 years who received 3 doses (0, 2, 6 month schedule). Six additional studies found similar results for 4vHPV and 2vHPV ( 6). Immunogenicity \\nwas found to be noninferior with 2 doses in persons aged 9 through 14 years compared with 3 doses in a group in which clinical efficacy was demonstrated (GRADE evidence type 3).\\nEfficacy and effectiveness.  Although efficacy and postlicen -\\nsure effectiveness studies were reviewed, none met the inclusion criteria detailed above. The prelicensure HPV vaccine efficacy \\ntrials were conducted with 3-dose series; post hoc analyses con -\\nducted with data from some of these trials found high efficacy \\nagainst infection among vaccinees who received 2 doses and those who received 3 doses ( 9,10). A large study comparing \\n2 doses with 3 doses also suggested similar efficacy against infection (11). Postlicensure effectiveness studies have found lower effectiveness against various HPV-associated outcomes among vaccinees who received 2 doses compared with those who received 3 doses, but methodologic challenges with these \\nstudies limit interpretation of the findings.**\\nDuration of protection.  Through 10 years of follow-up \\nfrom clinical trials, no evidence of waning protection after \\na 3-dose series of HPV vaccine has been found ( 1). Because \\nantibody kinetics are similar with 2-dose and 3-dose series, duration of protection is also expected to be long-lasting after \\na 2-dose series (12,13).\\nHealth impact and cost-effectiveness modeling.  \\nPopulation-level effectiveness and cost-effectiveness of 2-dose \\nand 3-dose schedules of 9vHPV in the United States have been modeled ( 14). Assuming both efficacy and duration of protec -\\ntion are similar with either schedule, a 2-dose series would be cost-saving and have similar population impact to a 3-dose series. Even if duration of protection is 20 years for a 2-dose series and lifelong for a 3-dose series, additional benefits of a 3-dose series would be relatively small, and a 2-dose series would be more cost-effective (14).\\nRationale\\nHPV vaccines are highly effective and safe, and a powerful pre -\\nvention tool for reducing HPV infections and HPV-associated cancers (1 ,2). Based on the available immunogenicity evidence, \\na 2-dose schedule (0, 6–12 months) will have efficacy equivalent to a 3-dose schedule (0, 1–2, 6 months) if the HPV vaccination series is initiated before the 15th birthday (GRADE evidence type 3) (6 ). ACIP recommends a 2-dose schedule for HPV vac -\\ncination of girls and boys who initiate the vaccination series at ages 9 through 14 years (Category A recommendation).\\nRecommendations\\nRoutine and catch-up age groups.  ACIP recommends \\nroutine HPV vaccination at age 11 or 12 years. Vaccination can be given starting at age 9 years. ACIP also recommends \\nvaccination for females through age 26 years and for males \\nthrough age 21 years who were not adequately vaccinated previously. Males aged 22 through 26 years may be vaccinated. (See also: Special populations, Medical conditions)\\nDosing schedules. For persons initiating vaccination before \\ntheir 15th birthday, the recommended immunization sched -\\nule is 2 doses of HPV vaccine. The second dose should be \\n§ S tudies were excluded when 2-dose interval was not ≥5 months.\\n¶ T welve votes to none, with one recusal. * * I n studies conducted in the setting of a 3-dose HPV vaccine recommendation \\nor policy, many 2-dose recipients received HPV vaccine doses at a 1–2 month \\ninterval; in addition, 2-dose recipients differed from 3-dose recipients in ways \\nthat suggested differences in HPV exposure.Morbidity and Mortality Weekly ReportMMWR  / December 16, 2016  / V ol. 65  /  No. 49  1407\\nUS Department of Health and Human Services/Centers for Disease Control and Preventionadministered 6–12 months after the first dose (0, 6–12 month \\nschedule)†† (Table).\\nFor persons initiating vaccination on or after their 15th \\nbirthday, the recommended immunization schedule is 3 doses \\nof HPV vaccine. The second dose should be administered \\n1–2 months after the first dose, and the third dose should be administered 6 months after the first dose (0, 1–2, 6 month schedule)\\n§§ (Table).\\nPersons vaccinated previously. Persons who initiated vac -\\ncination with 9vHPV, 4vHPV, or 2vHPV before their 15th \\nbirthday, and received 2 doses of any HPV vaccine at the \\nrecommended dosing schedule (0, 6–12 months), or 3 doses of any HPV vaccine at the recommended dosing schedule (0, 1–2, 6 months), are considered adequately vaccinated.\\nPersons who initiated vaccination with 9vHPV, 4vHPV, or \\n2vHPV on or after their 15th birthday, and received 3 doses \\nof any HPV vaccine at the recommended dosing schedule, are \\nconsidered adequately vaccinated.\\n9vHPV may be used to continue or complete a vaccination \\nseries started with 4vHPV or 2vHPV.\\nFor persons who have been adequately vaccinated with \\n2vHPV or 4vHPV, there is no ACIP recommendation regard -\\ning additional vaccination with 9vHPV.\\nInterrupted schedules. If the vaccination schedule is inter -\\nrupted, the series does not need to be restarted. The number of recommended doses is based on age at administration of the first dose.Special populations. For children with a history of sexual \\nabuse or assault, ACIP recommends routine HPV vaccination beginning at age 9 years.\\nFor men who have sex with men,\\n¶¶ ACIP recommends \\nroutine HPV vaccination as for all males, and vaccination through age 26 years for those who were not adequately vac -\\ncinated previously.\\nFor transgender persons, ACIP recommends routine \\nHPV vaccination as for all adolescents, and vaccination through age 26 years for those who were not adequately vaccinated previously.\\nMedical conditions.  ACIP recommends vaccination with 3 \\ndoses of HPV vaccine (0, 1–2, 6 months) for females and males aged 9 through 26 years with primary or secondary immuno -\\ncompromising conditions that might reduce cell-mediated or humoral immunity,*** such as B lymphocyte antibody deficiencies, T lymphocyte complete or partial defects, HIV \\ninfection, malignant neoplasms, transplantation, autoimmune \\ndisease, or immunosuppressive therapy, because immune response to vaccination might be attenuated (Table) (7).\\nContraindications and precautions.  Contraindications \\nand precautions, including those related to pregnancy, are unchanged from previous recommendations ( 1,2). Adverse \\nevents occurring after administration of any vaccine should be reported to the Vaccine Adverse Event Reporting System (VAERS). Reports can be submitted to VAERS online, by fax, or by mail. Additional information about VAERS is available by telephone (1-800-822-7967) or online ( https://vaers.hhs.gov ).TABLE. Recommended number of doses and intervals for human papillomavirus (HPV) vaccine, by age at series initiation and medical conditions — \\nUnited States, 2016\\nPopulationRecommended number of \\nHPV vaccine dosesRecommended interval \\nbetween doses\\nPersons initiating HPV vaccination at ages 9 through 14 years,* except \\nimmunocompromised persons†2 0, 6–12 months§\\nPersons initiating HPV vaccination at ages 15 through 26 years¶ and \\nimmunocompromised persons† initiating HPV vaccination at ages 9 through 26 years3 0, 1–2, 6 months**\\n * A CIP recommends routine HPV vaccination for adolescents at age 11 or 12 years; vaccination may be given starting at age 9 years.\\n † P ersons with primary or secondary immunocompromising conditions that might reduce cell-mediated or humoral immunity (see also: Medical conditions)\\n § I n a 2-dose schedule of HPV vaccine, the minimum interval between the first and second doses is 5 months.\\n ¶ F or persons who were not adequately vaccinated previously, ACIP recommends vaccination for females through age 26 years and for males through age \\n21 years; males ages 22 through 26 years may be vaccinated. Vaccination is recommended for some persons aged 22 through 26 years; see Medical conditions \\nand Special populations.\\n ** I n a 3-dose schedule of HPV vaccine, the minimum intervals are 4 weeks between the first and second doses, 12 weeks between the second and third doses, and \\n5 months between the first and third doses.\\n †† I n a 2-dose schedule of HPV vaccine, the minimum interval between the first \\nand second doses is 5 months. If the second dose is administered after a shorter \\ninterval, a third dose should be administered a minimum of 12 weeks after \\nthe second dose and a minimum of 5 months after the first dose.\\n §§ I n a 3-dose schedule of HPV vaccine, the minimum intervals are 4 weeks \\nbetween the first and second doses, 12 weeks between the second and third \\ndoses, and 5 months between the first and third doses. If a vaccine dose is \\nadministered after a shorter interval, it should be readministered after another \\nminimum interval has elapsed since the most recent dose. ¶¶ I ncluding men who identify as gay or bisexual, or who intend to have sex \\nwith men.\\n *** The r ecommendation for a 3-dose schedule of HPV vaccine does not apply \\nto children aged <15 years with asplenia, asthma, chronic granulomatous disease, chronic liver disease, chronic lung disease, chronic renal disease, \\ncentral nervous system anatomic barrier defects (e.g., cochlear implant), \\ncomplement deficiency, diabetes, heart disease, or sickle cell disease.Morbidity and Mortality Weekly Report 1408  MMWR  /  December 16, 2016  /  V ol. 65  /  No. 49\\nUS Department of Health and Human Services/Centers for Disease Control and PreventionAcknowledgments\\nMembers of the Advisory Committee on Immunization Practices \\n(ACIP) (member roster for July 2016–June 2017 is available online \\nat https://www.cdc.gov/vaccines/acip/committee/members-archive.\\nhtml); ACIP HPV Vaccines Work Group: Jorge E. Arana, MD, \\nAtlanta, Georgia; Joseph Bocchini, MD, Shreveport, Louisiana; Harrell Chesson, PhD, Atlanta, Georgia; Tamera Coyne-Beasley, MD, Chapel Hill, North Carolina; C. Robinette Curtis, MD, Atlanta, Georgia; Carolyn D. Deal, PhD, Bethesda, Maryland; Shelley Deeks, MD, Toronto, Ontario, Canada; John Douglas, MD, Greenwood Village, Colorado; Linda Eckert, MD, Seattle, Washington; Sandra Adamson Fryhofer, MD, Atlanta, Georgia; Julianne Gee, MPH, Atlanta, Georgia; Bruce G. Gellin, MD, Washington, DC; Samuel Katz, MD, Durham, North Carolina; Alison Kempe, MD, Denver, Colorado (Chair); Aimée R. Kreimer, PhD, Bethesda, Maryland; \\nJoohee Lee, MD, Silver Spring, Maryland; Lauri E. Markowitz, MD, Atlanta, Georgia (CDC Lead); Elissa Meites, MD, Atlanta, \\nGeorgia; Amy B. Middleman, MD, Oklahoma City, Oklahoma; Chris Nyquist, MD, Denver, Colorado; Sean O’Leary, MD, Aurora, Colorado; Sara E. Oliver, MD, Atlanta, Georgia; Cynthia Pellegrini, Washington, DC; Jeff Roberts, MD; Rockville, Maryland; José R. Romero, MD, Little Rock, Arkansas; Jeanne Santoli, MD, Atlanta, Georgia; Mona Saraiya, MD, Atlanta, Georgia; Debbie Saslow, PhD, Atlanta, Georgia; Margot Savoy, MD, Wilmington, Delaware; Shannon Stokley, DrPH, Atlanta, Georgia; Lakshmi Sukumaran, MD, Atlanta, Georgia; Elizabeth R. Unger, PhD, MD, Atlanta, Georgia; Patricia Whitley-Williams, MD, New Brunswick, New Jersey; Rodney Willoughby, MD, Wauwatosa, Wisconsin; JoEllen Wolicki, Atlanta, Georgia; Sixun Yang, MD, Rockville, Maryland; Jane Zucker, MD, New York, New York.\\n 1Division of Viral Diseases, National Center for Immunization and Respiratory \\nDiseases, CDC; 2HPV Vaccines Work Group, Advisory Committee on \\nImmunization Practices, Atlanta, Georgia; 3Department of Pediatrics, University \\nof Colorado Anschutz Medical Campus, Denver, Colorado.\\nCorresponding author: Elissa Meites, emeites@cdc.gov , 404-639-8253.\\nReferences\\n 1. M arkowitz LE, Dunne EF , Saraiya M, et al. Human papillomavirus \\nvaccination: recommendations of the Advisory Committee on Immunization \\nPractices (ACIP). MMWR Recomm Rep 2014;63(No. RR-05).\\n 2 . P etrosky E, Bocchini JA Jr, Hariri S, et al. Use of 9-valent human \\npapillomavirus (HPV) vaccine: updated HPV vaccination recommendations of the advisory committee on immunization practices. MMWR Morb Mortal Wkly Rep 2015;64:300–4.\\n 3 . V iens LJ, Henley SJ, Watson M, et al. Human papillomavirus-associated \\ncancers—United States, 2008–2012. MMWR Morb Mortal Wkly Rep 2016;65:661–6. http://dx.doi.org/10.15585/mmwr.mm6526a1 4 . I versen O-E, Miranda MJ, Ulied A, et al. Immunogenicity of the 9-valent \\nHPV vaccine using 2-dose regimens in girls and boys vs a 3-dose regimen in women. JAMA 2016;316:2411–21. http://dx.doi.org/10.1001/\\njama.2016.17615\\n 5 . F ood and Drug Administration. Prescribing information [package insert]. \\nGardasil 9 [human papillomavirus 9-valent vaccine, recombinant]. Silver Spring, MD: US Department of Health and Human Services, Food and Drug Administration; 2016. http://www.fda.gov/downloads/\\nBiologicsBloodVaccines/Vaccines/ApprovedProducts/UCM426457.pdf\\n 6. CDC. G rading of Recommendations Assessment, Development and \\nEvaluation (GRADE) of a 2-dose schedule for human papillomavirus (HPV) vaccination. Atlanta, GA: US Department of Health and Human Services, CDC; 2016. https://www.cdc.gov/vaccines/acip/recs/grade/\\nhpv-2-dose.html\\n 7. R ubin LG, Levin MJ, Ljungman P , et al.; Infectious Diseases Society of \\nAmerica. 2013 IDSA clinical practice guideline for vaccination of the immunocompromised host. Clin Infect Dis 2014;58:e44–100. http://\\ndx.doi.org/10.1093/cid/cit684\\n 8 . Ahmed F , Temte JL, Campos-Outcalt D, Schünemann HJ; ACIP \\nEvidence Based Recommendations Work Group (EBRWG). Methods for developing evidence-based recommendations by the Advisory Committee on Immunization Practices (ACIP) of the U.S. Centers for Disease Control and Prevention (CDC). Vaccine 2011;29:9171–6. http://dx.doi.org/10.1016/j.vaccine.2011.08.005\\n 9. Kr eimer AR, Struyf F , Del Rosario-Raymundo MR, et al.; Costa Rica \\nVaccine T rial Study Group Authors; PATRICIA Study Group Authors; HPV PATRICIA Principal Investigators/Co-Principal Investigator Collaborators; GSK Vaccines Clinical Study Support Group. Efficacy of fewer than three doses of an HPV-16/18 AS04-adjuvanted vaccine: combined analysis of data from the Costa Rica Vaccine and PATRICIA \\nT rials. Lancet Oncol 2015;16:775–86. http://dx.doi.org/10.1016/\\nS1470-2045(15)00047-9\\n 10. Kr eimer AR, Rodriguez AC, Hildesheim A, et al.; CVT Vaccine Group. \\nProof-of-principle evaluation of the efficacy of fewer than three doses \\nof a bivalent HPV16/18 vaccine. J Natl Cancer Inst 2011;103:1444–51. http://dx.doi.org/10.1093/jnci/djr319\\n 11. S ankaranarayanan R, Prabhu PR, Pawlita M, et al.; Indian HPV Vaccine \\nStudy Group. Immunogenicity and HPV infection after one, two, and three doses of quadrivalent HPV vaccine in girls in India: a multicentre prospective cohort study. Lancet Oncol 2016;17:67–77. http://dx.doi.\\norg/10.1016/S1470-2045(15)00414-3\\n 12. R omanowski B, Schwarz TF , Ferguson L, et al. Sustained immunogenicity \\nof the HPV-16/18 AS04-adjuvanted vaccine administered as a two-dose schedule in adolescent girls: five-year clinical data and modeling predictions from a randomized study. Hum Vaccin Immunother 2016;12:20–9. http://dx.doi.org/10.1080/21645515.2015.1065363\\n 13. D obson SR, McNeil S, Dionne M, et al. Immunogenicity of 2 doses of \\nHPV vaccine in younger adolescents vs 3 doses in young women: a randomized clinical trial. JAMA 2013;309:1793–802. http://dx.doi.\\norg/10.1001/jama.2013.1625\\n 14. Laprise JF , Markowitz LE, Chesson HW, Drolet M, Brisson M. \\nComparison of 2-dose and 3-dose 9-valent human papillomavirus vaccine schedules in the United States: a cost-effectiveness analysis. J Infect Dis 2016;214:685–8. http://dx.doi.org/10.1093/infdis/jiw227'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "passage_titles = []\n",
        "passages = []\n",
        "\n",
        "# Define a set of punctuation characters\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "# Get the set of stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for i in range(len(titles)):\n",
        "    title = titles[i]\n",
        "    article = articles[i]\n",
        "\n",
        "    if len(article) == 0:\n",
        "        print('Skipping empty article:', title)\n",
        "        continue\n",
        "\n",
        "    article = article.replace('\\n', '')  # Remove newline characters from the article\n",
        "\n",
        "    # Preprocess the passage\n",
        "    chunk_size = 700  # Number of characters in each chunk\n",
        "    start = 0\n",
        "    end = start + chunk_size\n",
        "\n",
        "    while start < len(article):\n",
        "        chunk = article[start:end]\n",
        "\n",
        "        # Lowercase the chunk\n",
        "        chunk = chunk.lower()\n",
        "\n",
        "        # Remove punctuation from the chunk\n",
        "        chunk = ''.join(char for char in chunk if char not in punctuation)\n",
        "\n",
        "        # Remove stop words from the chunk\n",
        "        chunk = ' '.join(word for word in chunk.split() if word not in stop_words)\n",
        "\n",
        "        if len(chunk) > 0:\n",
        "            passage_titles.append(title)\n",
        "            passages.append(chunk)\n",
        "\n",
        "        start = end\n",
        "        end = start + chunk_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXdgSkvIvR6g",
        "outputId": "edddf8a2-4ff9-4447-d379-f85feaccbdf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(passages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WQXuyBnaifY",
        "outputId": "fcae4966-fe16-4e02-d671-4d3a3e8cbf53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passages[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "2o-CSgX_rvSn",
        "outputId": "4176a0db-388d-4f75-fbe9-b4c30b68db66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1 12 years vaccination given starting age 9 years catchup vaccination recommended since 2006 females age 26 years since 2011 males age 21 years certain special populations age 26 years report updates acip catchup hpv vaccination recommendations guidance published 2014 2015 2016 1–3 routine recommendations vaccination adolescents changed june 2019 acip recommended catchup hpv vaccination persons age 26 years acip recommend catchup vaccination adults aged 27 45 years recognized persons adequately vaccinated might b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRQuestionEncoder, DPRContextEncoder, DPRQuestionEncoderTokenizerFast, DPRContextEncoderTokenizerFast\n",
        "import torch"
      ],
      "metadata": {
        "id": "e9oxz343qeuE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DPR context encoder and tokenizer\n",
        "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "\n",
        "# Set device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move model to device\n",
        "ctx_encoder = ctx_encoder.to(device=device)"
      ],
      "metadata": {
        "id": "NTavINzBpyD5",
        "outputId": "ebacea26-d49c-4148-d7eb-a95699c2f583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def is_relevant(question_embedding, passage):\n",
        "    # question_embedding = embed_question(question)\n",
        "    passage_embedding = embed_passage(passage)\n",
        "    \n",
        "    similarity_score = cosine_similarity(question_embedding, passage_embedding)\n",
        "    print(f\"Similarity score: {similarity_score}\")\n",
        "    # Define a threshold to determine relevance\n",
        "    relevance_threshold = 0.55\n",
        "    \n",
        "    if similarity_score > relevance_threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "9yovnHrSqcAR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "!pip install -U scikit-learn\n",
        "!pip install rank-bm25\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "-wUhSur-rFiK",
        "outputId": "c2d393a0-5b15-45c3-b2ff-725c38fe92c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank-bm25) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from rank_bm25 import BM25Okapi"
      ],
      "metadata": {
        "id": "NlqY9xxnsGIW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_passages(query, passages, relevance_threshold=0.5):\n",
        "    # Tokenize and preprocess the query and passages\n",
        "    tokenizer = TfidfVectorizer().build_tokenizer()\n",
        "    query_tokens = tokenizer(query)\n",
        "    passage_tokens = [tokenizer(passage) for passage in passages]\n",
        "\n",
        "    # Calculate the BM25 scores\n",
        "    bm25 = BM25Okapi(passage_tokens)\n",
        "    scores = bm25.get_scores(query_tokens)\n",
        "     # Print the scores\n",
        "    print(\"Scores:\")\n",
        "    for score in scores:\n",
        "        print(\"{:.6f}\".format(score))\n",
        "    # Classify passages as positive or negative based on relevance threshold\n",
        "    positive_passages = []\n",
        "    negative_passages = []\n",
        "    for passage, score in zip(passages, scores):\n",
        "        if score > relevance_threshold:\n",
        "            positive_passages.append(passage)\n",
        "        else:\n",
        "            negative_passages.append(passage)\n",
        "\n",
        "    return positive_passages, negative_passages\n"
      ],
      "metadata": {
        "id": "8t52YvaisFeY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_question(question):\n",
        "    q_encoder_model_name = \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "    q_tokenizer = DPRQuestionEncoderTokenizerFast.from_pretrained(q_encoder_model_name)\n",
        "    q_encoder = DPRQuestionEncoder.from_pretrained(q_encoder_model_name)\n",
        "    \n",
        "    input_ids = q_tokenizer.encode(question, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "    input_ids = input_ids.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = q_encoder(input_ids=input_ids)\n",
        "    \n",
        "    embeddings = outputs.pooler_output\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "def embed_passage(passage):\n",
        "    ctx_encoder_model_name = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
        "    ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(ctx_encoder_model_name)\n",
        "    ctx_encoder = DPRContextEncoder.from_pretrained(ctx_encoder_model_name)\n",
        "    \n",
        "    input_ids = ctx_tokenizer.encode(passage, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "    input_ids = input_ids.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = ctx_encoder(input_ids=input_ids)\n",
        "    \n",
        "    embeddings = outputs.pooler_output\n",
        "    \n",
        "    return embeddings \n"
      ],
      "metadata": {
        "id": "2K8PP_6_qVab"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "questions = [\n",
        "    \"When did the GARDASIL 9 recommendations change\",\n",
        "    \"What were the past three recommendation changes for GARDASIL 9\",\n",
        "    \"Is GARDASIL 9 recommended for adults\",\n",
        "    \"Does the ACIP recommend a one-dose GARDASIL 9\"\n",
        "]\n",
        "\n",
        "preprocessed_questions = \" \"\n",
        "\n",
        "for question in questions:\n",
        "    question = question.lower()  # Convert to lowercase for case insensitivity\n",
        "    question = question.replace(\"?\", \"\")  # Remove question marks\n",
        "    question = question.strip()  # Remove leading/trailing whitespaces\n",
        "    preprocessed_questions = preprocessed_questions + question + \" \"\n",
        "\n",
        "print(preprocessed_questions)\n",
        "\n",
        "preprocessed_questions = embed_question(preprocessed_questions)\n",
        "# positive_passages, negative_passages = classify_passages(question, passages) \n",
        "\n",
        "positive_passages = []\n",
        "negative_passages = []\n",
        "\n",
        "for passage in passages:\n",
        "  if is_relevant(preprocessed_questions, passage) == True:\n",
        "    positive_passages.append(passage)\n",
        "  else :\n",
        "    negative_passages.append(passage)\n",
        "\n",
        "\n",
        "print(f\"Positive Passages:{len(positive_passages)}\")\n",
        "\n",
        "print(f\"\\nNegative Passages:{len(negative_passages)}\")\n"
      ],
      "metadata": {
        "id": "p1DU_05Oqkv9",
        "outputId": "19059b9e-2b02-45f8-d594-e67715bc90d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " when did the gardasil 9 recommendations change what were the past three recommendation changes for gardasil 9 is gardasil 9 recommended for adults does the acip recommend a one-dose gardasil 9 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5831587]]\n",
            "Similarity score: [[0.64496017]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5447879]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5805813]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6407132]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.60824275]]\n",
            "Similarity score: [[0.6043192]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5603637]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59493554]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59823483]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56058925]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6005913]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5996354]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54595417]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.525333]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.60780716]]\n",
            "Similarity score: [[0.5943364]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54868174]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58995336]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6387467]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5870667]]\n",
            "Similarity score: [[0.48745432]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5289097]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55488414]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5910996]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49848458]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46410608]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4940973]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5309821]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5461872]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5492212]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5393595]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5902033]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5500281]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56154644]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57625943]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6800518]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6193137]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6084176]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.576053]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58978516]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.540377]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5355464]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54906523]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.60428864]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5526793]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5332745]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48178935]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54394317]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6201272]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56087077]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5659795]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59524953]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.63459265]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5776126]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5789354]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.60677767]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5912899]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49369934]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.43165118]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4541553]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49294114]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5803288]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5836706]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47587067]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5231362]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5660953]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5376653]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56435186]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57351667]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57352346]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5741623]]\n",
            "Similarity score: [[0.5235317]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4935866]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.43933964]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46635494]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55095637]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5867373]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56522024]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5135031]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58801955]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.535043]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56108856]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5097095]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5102139]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4971861]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48337817]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5874141]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5494419]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4624423]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59921443]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5457246]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5325214]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47100717]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5569895]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5251151]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5369361]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5325373]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55658925]]\n",
            "Similarity score: [[0.5759756]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54429317]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5260732]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56806177]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.566054]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5664443]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5709995]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50053084]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5288358]]\n",
            "Similarity score: [[0.5443212]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56119347]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49195457]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5270766]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5799318]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4872875]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50562847]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5030903]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5451437]]\n",
            "Similarity score: [[0.5663147]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5553094]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5340131]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53072345]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49703625]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5373336]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53707373]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47891906]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5595894]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5136645]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5596073]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57026017]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5238844]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4493356]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.45133805]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6235465]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5626939]]\n",
            "Similarity score: [[0.6076773]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5218823]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.560048]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56886065]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5832514]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5308219]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55287695]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59143037]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5532567]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56377685]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5659504]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5046222]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5479093]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59251875]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.60711175]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5737227]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55205107]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56532454]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59422743]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5902302]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5678749]]\n",
            "Similarity score: [[0.51283073]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5516842]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55276066]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.63656926]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56420547]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6189532]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5513012]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46015137]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5668573]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53633904]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48523405]]\n",
            "Similarity score: [[0.51915765]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5275792]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54779834]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4914137]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5441589]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5466386]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5931548]]\n",
            "Similarity score: [[0.5904128]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5979433]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5688299]]\n",
            "Similarity score: [[0.5888944]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5738056]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.535174]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56892455]]\n",
            "Similarity score: [[0.57054824]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5745106]]\n",
            "Similarity score: [[0.6096097]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5667479]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51881206]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5594977]]\n",
            "Similarity score: [[0.5346435]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5622998]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57099295]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54066443]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57475674]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5273465]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47302857]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50886345]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54824734]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5381999]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50251937]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5062952]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55867624]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5941603]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5484847]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5322565]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5157896]]\n",
            "Similarity score: [[0.5677614]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5129853]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48947898]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50760674]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5170464]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46358776]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5153657]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49454948]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48394555]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5608058]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55977654]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4910447]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5708522]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54820865]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5278218]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55296224]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5166638]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5316688]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5385332]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.61864316]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.500664]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56928563]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.62521935]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58214617]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48317647]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46839494]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5071889]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5469209]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58414185]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46403483]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5097605]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6083588]]\n",
            "Similarity score: [[0.57604194]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5250108]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5620327]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50531673]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5381228]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5468142]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5288337]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52243674]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5976796]]\n",
            "Similarity score: [[0.51897883]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.45188275]]\n",
            "Similarity score: [[0.4727085]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52077174]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50192875]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52948]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52717125]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5010844]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5515934]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51983166]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51788193]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48743117]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53213143]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5155158]]\n",
            "Similarity score: [[0.5380502]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48511922]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4494147]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4707473]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5270294]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5596855]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5060125]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5170972]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5830146]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5460999]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5145487]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58293295]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6035907]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5368481]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.540031]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55517995]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4856702]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5346184]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54323494]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.61032325]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57703245]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48247164]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5572733]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5123088]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57061064]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55373204]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51333666]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55313945]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5351503]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57850194]]\n",
            "Similarity score: [[0.54370975]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55128133]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5814206]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54165244]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5073495]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.59750664]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5155921]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5656341]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5926674]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6095594]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53271115]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5165205]]\n",
            "Similarity score: [[0.56074876]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.572326]]\n",
            "Similarity score: [[0.56678015]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5675548]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5539943]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5519102]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5790486]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5761193]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5975635]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5176753]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5422357]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5687005]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5081213]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5424371]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5859077]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54045737]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.533674]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5404199]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5536428]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51986736]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5777587]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6108008]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4786593]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58455473]]\n",
            "Similarity score: [[0.5734106]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5427195]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55584764]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5713278]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5559585]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5376184]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56446177]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57392085]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54064435]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5760252]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5742148]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5145457]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5458022]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5414005]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58227277]]\n",
            "Similarity score: [[0.5691292]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57871747]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52774376]]\n",
            "Similarity score: [[0.57445496]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53922373]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5806513]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5306278]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56007314]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5160233]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57699925]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58140695]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6271806]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.572518]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54105616]]\n",
            "Similarity score: [[0.5807971]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52945054]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.547926]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58850276]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54790425]]\n",
            "Similarity score: [[0.55612385]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.557432]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56675756]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53563213]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.63422066]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54159755]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5727353]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.63887125]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.570323]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5863152]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.61213183]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58275]]\n",
            "Similarity score: [[0.57628435]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55246747]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54029083]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49533093]]\n",
            "Similarity score: [[0.58808744]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55799925]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49103686]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5443163]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56310225]]\n",
            "Similarity score: [[0.5180774]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5479655]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54098326]]\n",
            "Similarity score: [[0.5443139]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5362619]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56362534]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5867526]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5736795]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55078405]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.57293737]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5712376]]\n",
            "Similarity score: [[0.5641905]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5125285]]\n",
            "Similarity score: [[0.47940898]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55432665]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6032554]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51286846]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5201618]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49102452]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47997564]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48817647]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4639683]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47217178]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52522165]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5007755]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47082698]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48665336]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.44837308]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46344367]]\n",
            "Similarity score: [[0.5103955]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.43651015]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5060934]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49819094]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.453668]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4988351]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5639751]]\n",
            "Similarity score: [[0.4865929]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46394348]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54050833]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4538127]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.44775122]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.49732956]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53391314]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.55545515]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51612544]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.51015425]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5572327]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5633228]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5449922]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52538735]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.52581215]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5597694]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5830695]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5303291]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5224403]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5300747]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5542506]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5262421]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53164715]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5454944]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.48759454]]\n",
            "Similarity score: [[0.52522206]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.53966576]]\n",
            "Similarity score: [[0.50179666]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5129925]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5344252]]\n",
            "Similarity score: [[0.5485525]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.6098876]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.56273365]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5354492]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.50187993]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.58879256]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.54220355]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4345164]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46843946]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46799946]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5129572]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.4945684]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.5652101]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.504857]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.44311512]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.46982446]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.47030184]]\n",
            "Similarity score: [[0.5134253]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score: [[0.452641]]\n",
            "Positive Passages:213\n",
            "\n",
            "Negative Passages:251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for np in positive_passages:\n",
        "#   print(np)\n",
        "#   # print(\"\\n\")"
      ],
      "metadata": {
        "id": "4p-Rv9NNtjYB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "dataset = []\n",
        "\n",
        "for positive_passage in positive_passages:\n",
        "    # Randomly select a subset of negative passages\n",
        "    negative_subset = random.sample(negative_passages, k=3)\n",
        "    \n",
        "    # Create a dictionary with positive and negative passages\n",
        "    example = {\n",
        "        \"positive_passages\": positive_passage,\n",
        "        \"negative_passages\": negative_subset\n",
        "    }\n",
        "    \n",
        "    # Add the example to the dataset\n",
        "    dataset.append(example) "
      ],
      "metadata": {
        "id": "lyiw1VfCqnUE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01\n",
        "margin_loss = 0.2\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(ctx_encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "# Define loss function\n",
        "loss_fn = torch.nn.MarginRankingLoss(margin=margin_loss)\n",
        "\n",
        "# Indexing and encoding steps\n",
        "\n",
        "# Define your dataset and other necessary preprocessing steps\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "margin = 0.3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epochs: {epoch}\")\n",
        "    total_loss = 0.0\n",
        "    ctx_encoder.train()\n",
        "    for i in range(0, len(dataset)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get a batch of positive and negative passages\n",
        "        batch = dataset[i]\n",
        "        positive_passages = batch[\"positive_passages\"]\n",
        "        negative_passages = batch[\"negative_passages\"]\n",
        "\n",
        "        # Encode passages\n",
        "      \n",
        "        positive_encodings = ctx_tokenizer(positive_passages, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "        negative_encodings = ctx_tokenizer(negative_passages, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Pass the encodings through the context encoder\n",
        "        positive_outputs = ctx_encoder(**positive_encodings)\n",
        "        negative_outputs = ctx_encoder(**negative_encodings) \n",
        "\n",
        "        # Get the pooler output\n",
        "        positive_embeddings = positive_outputs.pooler_output\n",
        "        negative_embeddings = negative_outputs.pooler_output\n",
        "\n",
        "        # Calculate similarity scores\n",
        "        similarity_scores = torch.cosine_similarity(positive_embeddings, negative_embeddings)\n",
        "        # print(f\"Simliarity score: {similarity_scores}\")\n",
        "        # similarity_scores.requires_grad = True \n",
        "\n",
        "        target = torch.ones_like(similarity_scores)\n",
        "        target[0] = -1\n",
        "\n",
        "        # Calculate loss\n",
        "        # loss = torch.max(torch.zeros_like(target), similarity_scores - similarity_scores[0] + margin).mean()\n",
        "        # loss = torch.max(torch.zeros_like(target), -similarity_scores + margin).mean()\n",
        "        # print(f\"Loss : {loss}\")\n",
        "        # loss = loss_fn(similarity_scores, target)\n",
        "        loss = loss_fn(similarity_scores, torch.zeros_like(target), target)\n",
        "        print(f\"Loss : {loss}\")\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    avg_loss = total_loss / len(dataset)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "output_dir = \"path_to_save_model\"\n",
        "ctx_encoder.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "qAmiaBsgqoHZ",
        "outputId": "33aa3c3c-0a98-47ee-f454-37cfadf50449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0\n",
            "Loss : 0.3319539427757263\n",
            "Loss : 0.2881055772304535\n",
            "Loss : 0.27423790097236633\n",
            "Loss : 0.26856592297554016\n",
            "Loss : 0.3033183515071869\n",
            "Loss : 0.22717617452144623\n",
            "Loss : 0.22716806828975677\n",
            "Loss : 0.23089884221553802\n",
            "Loss : 0.23034290969371796\n",
            "Loss : 0.14526422321796417\n",
            "Loss : 0.1918741911649704\n",
            "Loss : 0.2044406682252884\n",
            "Loss : 0.20573987066745758\n",
            "Loss : 0.16163523495197296\n",
            "Loss : 0.1995576024055481\n",
            "Loss : 0.1832420825958252\n",
            "Loss : 0.17823326587677002\n",
            "Loss : 0.18737900257110596\n",
            "Loss : 0.12880146503448486\n",
            "Loss : 0.16723133623600006\n",
            "Loss : 0.1423642635345459\n",
            "Loss : 0.1560448557138443\n",
            "Loss : 0.21327942609786987\n",
            "Loss : 0.17588786780834198\n",
            "Loss : 0.1133682131767273\n",
            "Loss : 0.1754542589187622\n",
            "Loss : 0.16004346311092377\n",
            "Loss : 0.09643205255270004\n",
            "Loss : 0.1184748187661171\n",
            "Loss : 0.16434209048748016\n",
            "Loss : 0.1886276751756668\n",
            "Loss : 0.20506931841373444\n",
            "Loss : 0.16832292079925537\n",
            "Loss : 0.16044284403324127\n",
            "Loss : 0.19657796621322632\n",
            "Loss : 0.19620151817798615\n",
            "Loss : 0.1548122614622116\n",
            "Loss : 0.10710906237363815\n",
            "Loss : 0.1460108608007431\n",
            "Loss : 0.15703840553760529\n",
            "Loss : 0.15744446218013763\n",
            "Loss : 0.15665900707244873\n",
            "Loss : 0.15108780562877655\n",
            "Loss : 0.22287791967391968\n",
            "Loss : 0.16958265006542206\n",
            "Loss : 0.1710462123155594\n",
            "Loss : 0.1846938133239746\n",
            "Loss : 0.15170328319072723\n",
            "Loss : 0.14960168302059174\n",
            "Loss : 0.1445443481206894\n",
            "Loss : 0.17192566394805908\n",
            "Loss : 0.1484125405550003\n",
            "Loss : 0.1675134152173996\n",
            "Loss : 0.12130936235189438\n",
            "Loss : 0.1567033976316452\n",
            "Loss : 0.1422838568687439\n",
            "Loss : 0.13143068552017212\n",
            "Loss : 0.20848985016345978\n",
            "Loss : 0.15487323701381683\n",
            "Loss : 0.1473710685968399\n",
            "Loss : 0.169777050614357\n",
            "Loss : 0.18989144265651703\n",
            "Loss : 0.12850677967071533\n",
            "Loss : 0.16809378564357758\n",
            "Loss : 0.11683502048254013\n",
            "Loss : 0.15698666870594025\n",
            "Loss : 0.14931362867355347\n",
            "Loss : 0.1870863437652588\n",
            "Loss : 0.19744883477687836\n",
            "Loss : 0.10234049707651138\n",
            "Loss : 0.13407160341739655\n",
            "Loss : 0.10341861099004745\n",
            "Loss : 0.17261089384555817\n",
            "Loss : 0.16557209193706512\n",
            "Loss : 0.10064063221216202\n",
            "Loss : 0.16907189786434174\n",
            "Loss : 0.18758954107761383\n",
            "Loss : 0.12901215255260468\n",
            "Loss : 0.11400230973958969\n",
            "Loss : 0.1884220391511917\n",
            "Loss : 0.15430480241775513\n",
            "Loss : 0.1370849758386612\n",
            "Loss : 0.10946231335401535\n",
            "Loss : 0.17852918803691864\n",
            "Loss : 0.18379127979278564\n",
            "Loss : 0.1505230814218521\n",
            "Loss : 0.13938413560390472\n",
            "Loss : 0.14387445151805878\n",
            "Loss : 0.1360945850610733\n",
            "Loss : 0.13818983733654022\n",
            "Loss : 0.17421436309814453\n",
            "Loss : 0.16802656650543213\n",
            "Loss : 0.15484382212162018\n",
            "Loss : 0.15666253864765167\n",
            "Loss : 0.1827622801065445\n",
            "Loss : 0.15556101500988007\n",
            "Loss : 0.1781264990568161\n",
            "Loss : 0.17592470347881317\n",
            "Loss : 0.19477899372577667\n",
            "Loss : 0.14656545221805573\n",
            "Loss : 0.1685727834701538\n",
            "Loss : 0.147576704621315\n",
            "Loss : 0.14230605959892273\n",
            "Loss : 0.1500379890203476\n",
            "Loss : 0.13100188970565796\n",
            "Loss : 0.14236140251159668\n",
            "Loss : 0.14328469336032867\n",
            "Loss : 0.1452016681432724\n",
            "Loss : 0.1285603642463684\n",
            "Loss : 0.10744168609380722\n",
            "Loss : 0.14749598503112793\n",
            "Loss : 0.16197989881038666\n",
            "Loss : 0.11808659881353378\n",
            "Loss : 0.17943304777145386\n",
            "Loss : 0.1442199945449829\n",
            "Loss : 0.19539302587509155\n",
            "Loss : 0.18238575756549835\n",
            "Loss : 0.22325249016284943\n",
            "Loss : 0.18413998186588287\n",
            "Loss : 0.17220444977283478\n",
            "Loss : 0.14384782314300537\n",
            "Loss : 0.15929043292999268\n",
            "Loss : 0.16052238643169403\n",
            "Loss : 0.13360680639743805\n",
            "Loss : 0.12226220220327377\n",
            "Loss : 0.15078198909759521\n",
            "Loss : 0.21286959946155548\n",
            "Loss : 0.14596623182296753\n",
            "Loss : 0.13773900270462036\n",
            "Loss : 0.15543052554130554\n",
            "Loss : 0.18475627899169922\n",
            "Loss : 0.1817428469657898\n",
            "Loss : 0.12941302359104156\n",
            "Loss : 0.1540561318397522\n",
            "Loss : 0.11695655435323715\n",
            "Loss : 0.1765243411064148\n",
            "Loss : 0.12822771072387695\n",
            "Loss : 0.15386706590652466\n",
            "Loss : 0.12549491226673126\n",
            "Loss : 0.12000665068626404\n",
            "Loss : 0.2067568302154541\n",
            "Loss : 0.1259949803352356\n",
            "Loss : 0.18469269573688507\n",
            "Loss : 0.1346919983625412\n",
            "Loss : 0.1865628957748413\n",
            "Loss : 0.16874969005584717\n",
            "Loss : 0.16908706724643707\n",
            "Loss : 0.10823234170675278\n",
            "Loss : 0.1620926707983017\n",
            "Loss : 0.12470349669456482\n",
            "Loss : 0.14762692153453827\n",
            "Loss : 0.19873130321502686\n",
            "Loss : 0.13491491973400116\n",
            "Loss : 0.15078237652778625\n",
            "Loss : 0.1367158144712448\n",
            "Loss : 0.21780890226364136\n",
            "Loss : 0.13049918413162231\n",
            "Loss : 0.10646037012338638\n",
            "Loss : 0.20975196361541748\n",
            "Loss : 0.1789974421262741\n",
            "Loss : 0.17489539086818695\n",
            "Loss : 0.11736968904733658\n",
            "Loss : 0.06535287946462631\n",
            "Loss : 0.17426006495952606\n",
            "Loss : 0.14889518916606903\n",
            "Loss : 0.07764782011508942\n",
            "Loss : 0.21221743524074554\n",
            "Loss : 0.17845956981182098\n",
            "Loss : 0.1524309664964676\n",
            "Loss : 0.12329554557800293\n",
            "Loss : 0.12469132989645004\n",
            "Loss : 0.11739423125982285\n",
            "Loss : 0.17492373287677765\n",
            "Loss : 0.14078600704669952\n",
            "Loss : 0.1694737672805786\n",
            "Loss : 0.1390208899974823\n",
            "Loss : 0.18442372977733612\n",
            "Loss : 0.17851412296295166\n",
            "Loss : 0.1746780127286911\n",
            "Loss : 0.1626860350370407\n",
            "Loss : 0.16241854429244995\n",
            "Loss : 0.22365351021289825\n",
            "Loss : 0.17655248939990997\n",
            "Loss : 0.1571328490972519\n",
            "Loss : 0.1749023050069809\n",
            "Loss : 0.15572170913219452\n",
            "Loss : 0.16218973696231842\n",
            "Loss : 0.1473395973443985\n",
            "Loss : 0.14913131296634674\n",
            "Loss : 0.12130912393331528\n",
            "Loss : 0.14716702699661255\n",
            "Loss : 0.14360328018665314\n",
            "Loss : 0.12208052724599838\n",
            "Loss : 0.13313840329647064\n",
            "Loss : 0.13851197063922882\n",
            "Loss : 0.13078562915325165\n",
            "Loss : 0.12980230152606964\n",
            "Loss : 0.20309175550937653\n",
            "Loss : 0.1256287693977356\n",
            "Loss : 0.16933797299861908\n",
            "Loss : 0.16613106429576874\n",
            "Loss : 0.20004244148731232\n",
            "Loss : 0.14262884855270386\n",
            "Loss : 0.10587647557258606\n",
            "Loss : 0.18755246698856354\n",
            "Loss : 0.2410494089126587\n",
            "Loss : 0.14184753596782684\n",
            "Loss : 0.1280771940946579\n",
            "Loss : 0.17802850902080536\n",
            "Loss : 0.13134725391864777\n",
            "Loss : 0.19759111106395721\n",
            "Loss : 0.16279198229312897\n",
            "Loss : 0.1419498175382614\n",
            "Epoch 1/5 - Loss: 0.1616\n",
            "Epochs: 1\n",
            "Loss : 0.17117591202259064\n",
            "Loss : 0.17111249268054962\n",
            "Loss : 0.1200701966881752\n",
            "Loss : 0.10704760998487473\n",
            "Loss : 0.18401509523391724\n",
            "Loss : 0.11582372337579727\n",
            "Loss : 0.1640070527791977\n",
            "Loss : 0.11832177639007568\n",
            "Loss : 0.09835019707679749\n",
            "Loss : 0.14120137691497803\n",
            "Loss : 0.14128747582435608\n",
            "Loss : 0.11838962882757187\n",
            "Loss : 0.14488548040390015\n",
            "Loss : 0.14897434413433075\n",
            "Loss : 0.17114859819412231\n",
            "Loss : 0.13689282536506653\n",
            "Loss : 0.14257580041885376\n",
            "Loss : 0.1438596397638321\n",
            "Loss : 0.14140644669532776\n",
            "Loss : 0.14752711355686188\n",
            "Loss : 0.13288648426532745\n",
            "Loss : 0.10973131656646729\n",
            "Loss : 0.11973140388727188\n",
            "Loss : 0.10539329051971436\n",
            "Loss : 0.11132127046585083\n",
            "Loss : 0.062321167439222336\n",
            "Loss : 0.11967015266418457\n",
            "Loss : 0.12684708833694458\n",
            "Loss : 0.09138629585504532\n",
            "Loss : 0.10918452590703964\n",
            "Loss : 0.15859614312648773\n",
            "Loss : 0.11456368118524551\n",
            "Loss : 0.12263497710227966\n",
            "Loss : 0.11039192229509354\n",
            "Loss : 0.18859565258026123\n",
            "Loss : 0.16800658404827118\n",
            "Loss : 0.1867690533399582\n",
            "Loss : 0.1482553333044052\n",
            "Loss : 0.12850339710712433\n",
            "Loss : 0.11469518393278122\n",
            "Loss : 0.20308904349803925\n",
            "Loss : 0.16526995599269867\n",
            "Loss : 0.14542873203754425\n",
            "Loss : 0.14815682172775269\n",
            "Loss : 0.0790126696228981\n",
            "Loss : 0.11386871337890625\n",
            "Loss : 0.1479337364435196\n",
            "Loss : 0.15626604855060577\n",
            "Loss : 0.1171785220503807\n",
            "Loss : 0.12111631780862808\n",
            "Loss : 0.11614229530096054\n",
            "Loss : 0.105410635471344\n",
            "Loss : 0.14503179490566254\n",
            "Loss : 0.13847889006137848\n",
            "Loss : 0.14878079295158386\n",
            "Loss : 0.13781364262104034\n",
            "Loss : 0.09641162306070328\n",
            "Loss : 0.11164194345474243\n",
            "Loss : 0.10605135560035706\n",
            "Loss : 0.11334796994924545\n",
            "Loss : 0.08786062151193619\n",
            "Loss : 0.173148512840271\n",
            "Loss : 0.13462571799755096\n",
            "Loss : 0.11310233920812607\n",
            "Loss : 0.09727158397436142\n",
            "Loss : 0.10641028732061386\n",
            "Loss : 0.13809935748577118\n",
            "Loss : 0.11124104261398315\n",
            "Loss : 0.10814528912305832\n",
            "Loss : 0.08948732167482376\n",
            "Loss : 0.1032387837767601\n",
            "Loss : 0.13679884374141693\n",
            "Loss : 0.10133203119039536\n",
            "Loss : 0.17003734409809113\n",
            "Loss : 0.13364852964878082\n",
            "Loss : 0.1265748292207718\n",
            "Loss : 0.12379065155982971\n",
            "Loss : 0.08005145937204361\n",
            "Loss : 0.0668494701385498\n",
            "Loss : 0.09439834207296371\n",
            "Loss : 0.17516188323497772\n",
            "Loss : 0.11629649251699448\n",
            "Loss : 0.13365982472896576\n",
            "Loss : 0.14042575657367706\n",
            "Loss : 0.10485440492630005\n",
            "Loss : 0.09616726636886597\n",
            "Loss : 0.06596500426530838\n",
            "Loss : 0.06660644710063934\n",
            "Loss : 0.07216577231884003\n",
            "Loss : 0.09614184498786926\n",
            "Loss : 0.11104794591665268\n",
            "Loss : 0.17551350593566895\n",
            "Loss : 0.1677221804857254\n",
            "Loss : 0.13156302273273468\n",
            "Loss : 0.1260266751050949\n",
            "Loss : 0.07425428926944733\n",
            "Loss : 0.0922689214348793\n",
            "Loss : 0.08695761114358902\n",
            "Loss : 0.10091190785169601\n",
            "Loss : 0.14682193100452423\n",
            "Loss : 0.17836634814739227\n",
            "Loss : 0.15168236196041107\n",
            "Loss : 0.09147761017084122\n",
            "Loss : 0.11447039991617203\n",
            "Loss : 0.09295463562011719\n",
            "Loss : 0.08286190778017044\n",
            "Loss : 0.12008071690797806\n",
            "Loss : 0.061950188130140305\n",
            "Loss : 0.06549736857414246\n",
            "Loss : 0.13832561671733856\n",
            "Loss : 0.10689004510641098\n",
            "Loss : 0.11354240030050278\n",
            "Loss : 0.1401762217283249\n",
            "Loss : 0.16373267769813538\n",
            "Loss : 0.07494903355836868\n",
            "Loss : 0.12031853199005127\n",
            "Loss : 0.1535346657037735\n",
            "Loss : 0.15701626241207123\n",
            "Loss : 0.08109384775161743\n",
            "Loss : 0.10289877653121948\n",
            "Loss : 0.15527956187725067\n",
            "Loss : 0.15448562800884247\n",
            "Loss : 0.14192630350589752\n",
            "Loss : 0.04682818055152893\n",
            "Loss : 0.046873267740011215\n",
            "Loss : 0.09277788549661636\n",
            "Loss : 0.11455146223306656\n",
            "Loss : 0.13494373857975006\n",
            "Loss : 0.09775057435035706\n",
            "Loss : 0.15843628346920013\n",
            "Loss : 0.06667058914899826\n",
            "Loss : 0.12490537017583847\n",
            "Loss : 0.09341777116060257\n",
            "Loss : 0.11459675431251526\n",
            "Loss : 0.11807648092508316\n",
            "Loss : 0.09708908945322037\n",
            "Loss : 0.09999512881040573\n",
            "Loss : 0.14814837276935577\n",
            "Loss : 0.12918882071971893\n",
            "Loss : 0.08245235681533813\n",
            "Loss : 0.12610119581222534\n",
            "Loss : 0.05199766159057617\n",
            "Loss : 0.09258272498846054\n",
            "Loss : 0.10619356483221054\n",
            "Loss : 0.2007899135351181\n",
            "Loss : 0.11491654068231583\n",
            "Loss : 0.05710366740822792\n",
            "Loss : 0.06306030601263046\n",
            "Loss : 0.0828385278582573\n",
            "Loss : 0.10751666873693466\n",
            "Loss : 0.13878373801708221\n",
            "Loss : 0.10903099924325943\n",
            "Loss : 0.15123878419399261\n",
            "Loss : 0.13207609951496124\n",
            "Loss : 0.09564455598592758\n",
            "Loss : 0.1424114853143692\n",
            "Loss : 0.12667541205883026\n",
            "Loss : 0.05017860606312752\n",
            "Loss : 0.18469059467315674\n",
            "Loss : 0.16012758016586304\n",
            "Loss : 0.09281488507986069\n",
            "Loss : 0.13052286207675934\n",
            "Loss : 0.0741729885339737\n",
            "Loss : 0.1305961161851883\n",
            "Loss : 0.11813700199127197\n",
            "Loss : 0.06255943328142166\n",
            "Loss : 0.09945515543222427\n",
            "Loss : 0.11198391765356064\n",
            "Loss : 0.0565037727355957\n",
            "Loss : 0.05820551887154579\n",
            "Loss : 0.10348839312791824\n",
            "Loss : 0.0987456664443016\n",
            "Loss : 0.15564458072185516\n",
            "Loss : 0.05069221183657646\n",
            "Loss : 0.12842603027820587\n",
            "Loss : 0.09313732385635376\n",
            "Loss : 0.10300468653440475\n",
            "Loss : 0.14681538939476013\n",
            "Loss : 0.0664825513958931\n",
            "Loss : 0.09218452125787735\n",
            "Loss : 0.07212147861719131\n",
            "Loss : 0.11509018391370773\n",
            "Loss : 0.18374474346637726\n",
            "Loss : 0.15233083069324493\n",
            "Loss : 0.10988056659698486\n",
            "Loss : 0.0665089562535286\n",
            "Loss : 0.11945497989654541\n",
            "Loss : 0.07850708812475204\n",
            "Loss : 0.15331321954727173\n",
            "Loss : 0.07615235447883606\n",
            "Loss : 0.03546937182545662\n",
            "Loss : 0.12503795325756073\n",
            "Loss : 0.040413957089185715\n",
            "Loss : 0.09048368781805038\n",
            "Loss : 0.16562682390213013\n",
            "Loss : 0.12304861098527908\n",
            "Loss : 0.05815034732222557\n",
            "Loss : 0.08915773779153824\n",
            "Loss : 0.10393238067626953\n",
            "Loss : 0.13221092522144318\n",
            "Loss : 0.06777967512607574\n",
            "Loss : 0.11366984248161316\n",
            "Loss : 0.10073792189359665\n",
            "Loss : 0.07310695201158524\n",
            "Loss : 0.15185923874378204\n",
            "Loss : 0.11140923947095871\n",
            "Loss : 0.08464909344911575\n",
            "Loss : 0.1386471539735794\n",
            "Loss : 0.14041246473789215\n",
            "Loss : 0.07252006232738495\n",
            "Loss : 0.2114272266626358\n",
            "Loss : 0.10989519953727722\n",
            "Loss : 0.16493584215641022\n",
            "Epoch 2/5 - Loss: 0.1173\n",
            "Epochs: 2\n",
            "Loss : 0.14757929742336273\n",
            "Loss : 0.1862960010766983\n",
            "Loss : 0.16037188470363617\n",
            "Loss : 0.08784633874893188\n",
            "Loss : 0.1472720503807068\n",
            "Loss : 0.09667685627937317\n",
            "Loss : 0.1302284598350525\n",
            "Loss : 0.06287281960248947\n",
            "Loss : 0.1437767595052719\n",
            "Loss : 0.17538456618785858\n",
            "Loss : 0.0848434567451477\n",
            "Loss : 0.0817226991057396\n",
            "Loss : 0.1489524245262146\n",
            "Loss : 0.14627628028392792\n",
            "Loss : 0.18102912604808807\n",
            "Loss : 0.1184023842215538\n",
            "Loss : 0.1002788320183754\n",
            "Loss : 0.14592775702476501\n",
            "Loss : 0.10511545091867447\n",
            "Loss : 0.12860727310180664\n",
            "Loss : 0.15507958829402924\n",
            "Loss : 0.09339193254709244\n",
            "Loss : 0.09422922134399414\n",
            "Loss : 0.11642882972955704\n",
            "Loss : 0.11645090579986572\n",
            "Loss : 0.09592143446207047\n",
            "Loss : 0.09297709912061691\n",
            "Loss : 0.13828414678573608\n",
            "Loss : 0.10383051633834839\n",
            "Loss : 0.1435869038105011\n",
            "Loss : 0.06720640510320663\n",
            "Loss : 0.09108567982912064\n",
            "Loss : 0.1243973895907402\n",
            "Loss : 0.07797238230705261\n",
            "Loss : 0.12235862016677856\n",
            "Loss : 0.16718943417072296\n",
            "Loss : 0.18493998050689697\n",
            "Loss : 0.12973235547542572\n",
            "Loss : 0.08613157272338867\n",
            "Loss : 0.13766928017139435\n",
            "Loss : 0.20734389126300812\n",
            "Loss : 0.07045713067054749\n",
            "Loss : 0.1590539813041687\n",
            "Loss : 0.1271412968635559\n",
            "Loss : 0.08726101368665695\n",
            "Loss : 0.11046222597360611\n",
            "Loss : 0.1375230997800827\n",
            "Loss : 0.0834105983376503\n",
            "Loss : 0.1249978169798851\n",
            "Loss : 0.08763732761144638\n",
            "Loss : 0.11542443186044693\n",
            "Loss : 0.08371013402938843\n",
            "Loss : 0.13812877237796783\n",
            "Loss : 0.1315821260213852\n",
            "Loss : 0.10285269469022751\n",
            "Loss : 0.10084225982427597\n",
            "Loss : 0.09086868911981583\n",
            "Loss : 0.12176414579153061\n",
            "Loss : 0.07249071449041367\n",
            "Loss : 0.14965100586414337\n",
            "Loss : 0.1661386340856552\n",
            "Loss : 0.13397212326526642\n",
            "Loss : 0.0791298896074295\n",
            "Loss : 0.11160764843225479\n",
            "Loss : 0.08891639858484268\n",
            "Loss : 0.08212746679782867\n",
            "Loss : 0.12194075435400009\n",
            "Loss : 0.11968217045068741\n",
            "Loss : 0.08601424843072891\n",
            "Loss : 0.05110645666718483\n",
            "Loss : 0.0706472396850586\n",
            "Loss : 0.1243462786078453\n",
            "Loss : 0.1071353331208229\n",
            "Loss : 0.0990285649895668\n",
            "Loss : 0.08502868562936783\n",
            "Loss : 0.09353790432214737\n",
            "Loss : 0.1208520233631134\n",
            "Loss : 0.07678795605897903\n",
            "Loss : 0.06034708395600319\n",
            "Loss : 0.1104646697640419\n",
            "Loss : 0.16627590358257294\n",
            "Loss : 0.10149911046028137\n",
            "Loss : 0.07777274399995804\n",
            "Loss : 0.13550330698490143\n",
            "Loss : 0.09590204805135727\n",
            "Loss : 0.11171279102563858\n",
            "Loss : 0.08751089125871658\n",
            "Loss : 0.05924845114350319\n",
            "Loss : 0.05854899808764458\n",
            "Loss : 0.1188708171248436\n",
            "Loss : 0.09296900033950806\n",
            "Loss : 0.09036918729543686\n",
            "Loss : 0.13219787180423737\n",
            "Loss : 0.13405893743038177\n",
            "Loss : 0.10562536865472794\n",
            "Loss : 0.06744541972875595\n",
            "Loss : 0.08590809255838394\n",
            "Loss : 0.07454530149698257\n",
            "Loss : 0.09602633863687515\n",
            "Loss : 0.10614655166864395\n",
            "Loss : 0.13312353193759918\n",
            "Loss : 0.08661806583404541\n",
            "Loss : 0.0918545126914978\n",
            "Loss : 0.09713399410247803\n",
            "Loss : 0.09690209478139877\n",
            "Loss : 0.06623198837041855\n",
            "Loss : 0.059603963047266006\n",
            "Loss : 0.07621986418962479\n",
            "Loss : 0.0625612810254097\n",
            "Loss : 0.09929323941469193\n",
            "Loss : 0.05453363060951233\n",
            "Loss : 0.09035297483205795\n",
            "Loss : 0.0890878364443779\n",
            "Loss : 0.1393943876028061\n",
            "Loss : 0.058949436992406845\n",
            "Loss : 0.08446157723665237\n",
            "Loss : 0.13642138242721558\n",
            "Loss : 0.14179418981075287\n",
            "Loss : 0.09130209684371948\n",
            "Loss : 0.07342644780874252\n",
            "Loss : 0.06319420784711838\n",
            "Loss : 0.05489368736743927\n",
            "Loss : 0.12854541838169098\n",
            "Loss : 0.07320307940244675\n",
            "Loss : 0.06973616778850555\n",
            "Loss : 0.07710923254489899\n",
            "Loss : 0.0719488188624382\n",
            "Loss : 0.14089906215667725\n",
            "Loss : 0.07260505110025406\n",
            "Loss : 0.15694932639598846\n",
            "Loss : 0.09893292188644409\n",
            "Loss : 0.1182054877281189\n",
            "Loss : 0.08589446544647217\n",
            "Loss : 0.13120149075984955\n",
            "Loss : 0.09533411264419556\n",
            "Loss : 0.11551713198423386\n",
            "Loss : 0.07148759812116623\n",
            "Loss : 0.10140680521726608\n",
            "Loss : 0.06314918398857117\n",
            "Loss : 0.08901316672563553\n",
            "Loss : 0.08085865527391434\n",
            "Loss : 0.07460552453994751\n",
            "Loss : 0.07314570993185043\n",
            "Loss : 0.08448504656553268\n",
            "Loss : 0.22797735035419464\n",
            "Loss : 0.12085547298192978\n",
            "Loss : 0.10240984708070755\n",
            "Loss : 0.07545588910579681\n",
            "Loss : 0.09172558784484863\n",
            "Loss : 0.06312556564807892\n",
            "Loss : 0.12603454291820526\n",
            "Loss : 0.12063584476709366\n",
            "Loss : 0.1210152730345726\n",
            "Loss : 0.09957841783761978\n",
            "Loss : 0.06252618879079819\n",
            "Loss : 0.1030561551451683\n",
            "Loss : 0.07304073125123978\n",
            "Loss : 0.048831965774297714\n",
            "Loss : 0.13043330609798431\n",
            "Loss : 0.1134214997291565\n",
            "Loss : 0.10124329477548599\n",
            "Loss : 0.11882948130369186\n",
            "Loss : 0.04005343094468117\n",
            "Loss : 0.2390628457069397\n",
            "Loss : 0.119587242603302\n",
            "Loss : 0.09270187467336655\n",
            "Loss : 0.1194601058959961\n",
            "Loss : 0.10768043994903564\n",
            "Loss : 0.03585537150502205\n",
            "Loss : 0.06319301575422287\n",
            "Loss : 0.07587706297636032\n",
            "Loss : 0.11837033182382584\n",
            "Loss : 0.10597866773605347\n",
            "Loss : 0.04786163568496704\n",
            "Loss : 0.1034981906414032\n",
            "Loss : 0.07959763705730438\n",
            "Loss : 0.10699532181024551\n",
            "Loss : 0.08807655423879623\n",
            "Loss : 0.042242567986249924\n",
            "Loss : 0.09517893940210342\n",
            "Loss : 0.08407209068536758\n",
            "Loss : 0.14678652584552765\n",
            "Loss : 0.15898045897483826\n",
            "Loss : 0.09560801833868027\n",
            "Loss : 0.09185496717691422\n",
            "Loss : 0.07050948590040207\n",
            "Loss : 0.13430605828762054\n",
            "Loss : 0.08606978505849838\n",
            "Loss : 0.137991800904274\n",
            "Loss : 0.0749334767460823\n",
            "Loss : 0.04523531720042229\n",
            "Loss : 0.07035420089960098\n",
            "Loss : 0.05219871923327446\n",
            "Loss : 0.08583863824605942\n",
            "Loss : 0.08607393503189087\n",
            "Loss : 0.08481228351593018\n",
            "Loss : 0.09533903002738953\n",
            "Loss : 0.15156640112400055\n",
            "Loss : 0.09557827562093735\n",
            "Loss : 0.1236371397972107\n",
            "Loss : 0.07052682340145111\n",
            "Loss : 0.1009434163570404\n",
            "Loss : 0.08816388249397278\n",
            "Loss : 0.05805689096450806\n",
            "Loss : 0.11054408550262451\n",
            "Loss : 0.12202999740839005\n",
            "Loss : 0.06782989203929901\n",
            "Loss : 0.13615606725215912\n",
            "Loss : 0.11453127861022949\n",
            "Loss : 0.05048296973109245\n",
            "Loss : 0.16640593111515045\n",
            "Loss : 0.13479621708393097\n",
            "Loss : 0.1238228976726532\n",
            "Epoch 3/5 - Loss: 0.1039\n",
            "Epochs: 3\n",
            "Loss : 0.1445431262254715\n",
            "Loss : 0.13852043449878693\n",
            "Loss : 0.0885256826877594\n",
            "Loss : 0.1047811210155487\n",
            "Loss : 0.11592444777488708\n",
            "Loss : 0.12200272083282471\n",
            "Loss : 0.18284045159816742\n",
            "Loss : 0.09018399566411972\n",
            "Loss : 0.10805973410606384\n",
            "Loss : 0.17272989451885223\n",
            "Loss : 0.1008690595626831\n",
            "Loss : 0.10980790853500366\n",
            "Loss : 0.1387050896883011\n",
            "Loss : 0.09905796498060226\n",
            "Loss : 0.11681696027517319\n",
            "Loss : 0.1306544542312622\n",
            "Loss : 0.13034260272979736\n",
            "Loss : 0.1522648185491562\n",
            "Loss : 0.10114435106515884\n",
            "Loss : 0.1500633805990219\n",
            "Loss : 0.10991296917200089\n",
            "Loss : 0.11539290100336075\n",
            "Loss : 0.08473527431488037\n",
            "Loss : 0.07766170799732208\n",
            "Loss : 0.07514142245054245\n",
            "Loss : 0.06501144170761108\n",
            "Loss : 0.09488771110773087\n",
            "Loss : 0.09466729313135147\n",
            "Loss : 0.07681148499250412\n",
            "Loss : 0.18382561206817627\n",
            "Loss : 0.062340278178453445\n",
            "Loss : 0.12927280366420746\n",
            "Loss : 0.13056235015392303\n",
            "Loss : 0.07859709113836288\n",
            "Loss : 0.12517021596431732\n",
            "Loss : 0.16199061274528503\n",
            "Loss : 0.14633746445178986\n",
            "Loss : 0.1153283342719078\n",
            "Loss : 0.08072979003190994\n",
            "Loss : 0.14334289729595184\n",
            "Loss : 0.24839259684085846\n",
            "Loss : 0.08902696520090103\n",
            "Loss : 0.12968043982982635\n",
            "Loss : 0.1080021858215332\n",
            "Loss : 0.08278313279151917\n",
            "Loss : 0.11561963707208633\n",
            "Loss : 0.13792650401592255\n",
            "Loss : 0.10687949508428574\n",
            "Loss : 0.10136524587869644\n",
            "Loss : 0.10756051540374756\n",
            "Loss : 0.10729509592056274\n",
            "Loss : 0.1412225216627121\n",
            "Loss : 0.11119823902845383\n",
            "Loss : 0.09443571418523788\n",
            "Loss : 0.11855199187994003\n",
            "Loss : 0.09073936194181442\n",
            "Loss : 0.12767083942890167\n",
            "Loss : 0.11808415502309799\n",
            "Loss : 0.07222352176904678\n",
            "Loss : 0.13182799518108368\n",
            "Loss : 0.08852922916412354\n",
            "Loss : 0.1036122664809227\n",
            "Loss : 0.08750849217176437\n",
            "Loss : 0.09533245116472244\n",
            "Loss : 0.06437475979328156\n",
            "Loss : 0.06794753670692444\n",
            "Loss : 0.14215125143527985\n",
            "Loss : 0.08097280561923981\n",
            "Loss : 0.0893239751458168\n",
            "Loss : 0.06972886621952057\n",
            "Loss : 0.10106460005044937\n",
            "Loss : 0.08689016848802567\n",
            "Loss : 0.11258628964424133\n",
            "Loss : 0.14204393327236176\n",
            "Loss : 0.09242701530456543\n",
            "Loss : 0.06305420398712158\n",
            "Loss : 0.11134207248687744\n",
            "Loss : 0.04080114886164665\n",
            "Loss : 0.03744615241885185\n",
            "Loss : 0.1376188099384308\n",
            "Loss : 0.1480235606431961\n",
            "Loss : 0.07336567342281342\n",
            "Loss : 0.08256500959396362\n",
            "Loss : 0.11760642379522324\n",
            "Loss : 0.05409882962703705\n",
            "Loss : 0.06652738898992538\n",
            "Loss : 0.051005616784095764\n",
            "Loss : 0.06620640307664871\n",
            "Loss : 0.044741857796907425\n",
            "Loss : 0.14267002046108246\n",
            "Loss : 0.07302245497703552\n",
            "Loss : 0.1199105754494667\n",
            "Loss : 0.056829843670129776\n",
            "Loss : 0.11949974298477173\n",
            "Loss : 0.09297022223472595\n",
            "Loss : 0.059351950883865356\n",
            "Loss : 0.1057189479470253\n",
            "Loss : 0.05775448679924011\n",
            "Loss : 0.11071749776601791\n",
            "Loss : 0.07748394459486008\n",
            "Loss : 0.08948814868927002\n",
            "Loss : 0.06762131303548813\n",
            "Loss : 0.11884357780218124\n",
            "Loss : 0.09784701466560364\n",
            "Loss : 0.08074788004159927\n",
            "Loss : 0.08923893421888351\n",
            "Loss : 0.11336467415094376\n",
            "Loss : 0.06675799936056137\n",
            "Loss : 0.09616005420684814\n",
            "Loss : 0.10275661945343018\n",
            "Loss : 0.08428884297609329\n",
            "Loss : 0.08413328975439072\n",
            "Loss : 0.1047985851764679\n",
            "Loss : 0.17017994821071625\n",
            "Loss : 0.04592391476035118\n",
            "Loss : 0.08209311962127686\n",
            "Loss : 0.16161450743675232\n",
            "Loss : 0.14391128718852997\n",
            "Loss : 0.08803460747003555\n",
            "Loss : 0.08405685424804688\n",
            "Loss : 0.10610649734735489\n",
            "Loss : 0.06492556631565094\n",
            "Loss : 0.09335478395223618\n",
            "Loss : 0.04926744103431702\n",
            "Loss : 0.041566167026758194\n",
            "Loss : 0.06386712938547134\n",
            "Loss : 0.041358835995197296\n",
            "Loss : 0.08281368762254715\n",
            "Loss : 0.06790455430746078\n",
            "Loss : 0.16192202270030975\n",
            "Loss : 0.09273386001586914\n",
            "Loss : 0.09824097901582718\n",
            "Loss : 0.08030764758586884\n",
            "Loss : 0.114011250436306\n",
            "Loss : 0.12300225347280502\n",
            "Loss : 0.09460347890853882\n",
            "Loss : 0.038070715963840485\n",
            "Loss : 0.14641909301280975\n",
            "Loss : 0.10152214765548706\n",
            "Loss : 0.11127344518899918\n",
            "Loss : 0.10351463407278061\n",
            "Loss : 0.06475416570901871\n",
            "Loss : 0.07846149057149887\n",
            "Loss : 0.09563223272562027\n",
            "Loss : 0.17568254470825195\n",
            "Loss : 0.09181367605924606\n",
            "Loss : 0.07389453798532486\n",
            "Loss : 0.08121732622385025\n",
            "Loss : 0.06695006042718887\n",
            "Loss : 0.09859529882669449\n",
            "Loss : 0.11567142605781555\n",
            "Loss : 0.16492289304733276\n",
            "Loss : 0.1233915463089943\n",
            "Loss : 0.11621572822332382\n",
            "Loss : 0.10794714838266373\n",
            "Loss : 0.15283626317977905\n",
            "Loss : 0.13842977583408356\n",
            "Loss : 0.040394220501184464\n",
            "Loss : 0.18861497938632965\n",
            "Loss : 0.1545671820640564\n",
            "Loss : 0.12335735559463501\n",
            "Loss : 0.14153674244880676\n",
            "Loss : 0.04188043996691704\n",
            "Loss : 0.18974266946315765\n",
            "Loss : 0.10327345132827759\n",
            "Loss : 0.0731993168592453\n",
            "Loss : 0.09713634103536606\n",
            "Loss : 0.09230372309684753\n",
            "Loss : 0.04677281901240349\n",
            "Loss : 0.035076577216386795\n",
            "Loss : 0.06575606018304825\n",
            "Loss : 0.05680202320218086\n",
            "Loss : 0.12328474968671799\n",
            "Loss : 0.0634319931268692\n",
            "Loss : 0.06025014445185661\n",
            "Loss : 0.08269822597503662\n",
            "Loss : 0.09903666377067566\n",
            "Loss : 0.08932141214609146\n",
            "Loss : 0.027843058109283447\n",
            "Loss : 0.09130305051803589\n",
            "Loss : 0.08307398855686188\n",
            "Loss : 0.151529923081398\n",
            "Loss : 0.13391514122486115\n",
            "Loss : 0.11188151687383652\n",
            "Loss : 0.05699368193745613\n",
            "Loss : 0.10315189510583878\n",
            "Loss : 0.1330317109823227\n",
            "Loss : 0.06224912777543068\n",
            "Loss : 0.10533136129379272\n",
            "Loss : 0.04912957921624184\n",
            "Loss : 0.03349526599049568\n",
            "Loss : 0.09205702692270279\n",
            "Loss : 0.061759695410728455\n",
            "Loss : 0.10522618889808655\n",
            "Loss : 0.09290138632059097\n",
            "Loss : 0.10898243635892868\n",
            "Loss : 0.056791309267282486\n",
            "Loss : 0.1068602204322815\n",
            "Loss : 0.15362028777599335\n",
            "Loss : 0.10139194875955582\n",
            "Loss : 0.07526414096355438\n",
            "Loss : 0.1120724081993103\n",
            "Loss : 0.09180065244436264\n",
            "Loss : 0.08126357197761536\n",
            "Loss : 0.14267368614673615\n",
            "Loss : 0.13984039425849915\n",
            "Loss : 0.1322212666273117\n",
            "Loss : 0.1211698055267334\n",
            "Loss : 0.11125985532999039\n",
            "Loss : 0.037540484219789505\n",
            "Loss : 0.15899263322353363\n",
            "Loss : 0.11608429998159409\n",
            "Loss : 0.13268567621707916\n",
            "Epoch 4/5 - Loss: 0.1012\n",
            "Epochs: 4\n",
            "Loss : 0.11066188663244247\n",
            "Loss : 0.11580794304609299\n",
            "Loss : 0.11387596279382706\n",
            "Loss : 0.13102011382579803\n",
            "Loss : 0.1402338594198227\n",
            "Loss : 0.10126114636659622\n",
            "Loss : 0.15123558044433594\n",
            "Loss : 0.10730376094579697\n",
            "Loss : 0.13025546073913574\n",
            "Loss : 0.12970823049545288\n",
            "Loss : 0.12966397404670715\n",
            "Loss : 0.10483167320489883\n",
            "Loss : 0.14263798296451569\n",
            "Loss : 0.12237793207168579\n",
            "Loss : 0.18015830218791962\n",
            "Loss : 0.13861054182052612\n",
            "Loss : 0.13312898576259613\n",
            "Loss : 0.10897605866193771\n",
            "Loss : 0.09543776512145996\n",
            "Loss : 0.15494288504123688\n",
            "Loss : 0.136418879032135\n",
            "Loss : 0.11743005365133286\n",
            "Loss : 0.08820772171020508\n",
            "Loss : 0.07453371584415436\n",
            "Loss : 0.08067560940980911\n",
            "Loss : 0.07490929216146469\n",
            "Loss : 0.13895922899246216\n",
            "Loss : 0.13831518590450287\n",
            "Loss : 0.09712062031030655\n",
            "Loss : 0.16231274604797363\n",
            "Loss : 0.08218429237604141\n",
            "Loss : 0.09534285217523575\n",
            "Loss : 0.11688268184661865\n",
            "Loss : 0.08536824584007263\n",
            "Loss : 0.14591340720653534\n",
            "Loss : 0.1487310379743576\n",
            "Loss : 0.1380864828824997\n",
            "Loss : 0.10225830227136612\n",
            "Loss : 0.11751655489206314\n",
            "Loss : 0.10533950477838516\n",
            "Loss : 0.2375156432390213\n",
            "Loss : 0.09035750478506088\n",
            "Loss : 0.16017545759677887\n",
            "Loss : 0.10301440954208374\n",
            "Loss : 0.061990562826395035\n",
            "Loss : 0.09202004224061966\n",
            "Loss : 0.12535767257213593\n",
            "Loss : 0.07886804640293121\n",
            "Loss : 0.10731697082519531\n",
            "Loss : 0.09923895448446274\n",
            "Loss : 0.11637017875909805\n",
            "Loss : 0.08793944120407104\n",
            "Loss : 0.12997037172317505\n",
            "Loss : 0.12781314551830292\n",
            "Loss : 0.10160022974014282\n",
            "Loss : 0.0811414048075676\n",
            "Loss : 0.11136442422866821\n",
            "Loss : 0.14102648198604584\n",
            "Loss : 0.09069826453924179\n",
            "Loss : 0.15768587589263916\n",
            "Loss : 0.07527060061693192\n",
            "Loss : 0.1203593909740448\n",
            "Loss : 0.07381545752286911\n",
            "Loss : 0.08650770038366318\n",
            "Loss : 0.07637189328670502\n",
            "Loss : 0.08877447247505188\n",
            "Loss : 0.11947906017303467\n",
            "Loss : 0.0863337516784668\n",
            "Loss : 0.08962533622980118\n",
            "Loss : 0.07438909262418747\n",
            "Loss : 0.09384402632713318\n",
            "Loss : 0.10988696664571762\n",
            "Loss : 0.10009203106164932\n",
            "Loss : 0.11745551973581314\n",
            "Loss : 0.09472856670618057\n",
            "Loss : 0.08987388759851456\n",
            "Loss : 0.10007699579000473\n",
            "Loss : 0.05608418956398964\n",
            "Loss : 0.059162020683288574\n",
            "Loss : 0.11129029840230942\n",
            "Loss : 0.14083518087863922\n",
            "Loss : 0.09148267656564713\n",
            "Loss : 0.08291079849004745\n",
            "Loss : 0.10868541151285172\n",
            "Loss : 0.07063009589910507\n",
            "Loss : 0.0786384865641594\n",
            "Loss : 0.017848491668701172\n",
            "Loss : 0.05323408544063568\n",
            "Loss : 0.04093398526310921\n",
            "Loss : 0.0972152128815651\n",
            "Loss : 0.1068045124411583\n",
            "Loss : 0.08862218260765076\n",
            "Loss : 0.0888846293091774\n",
            "Loss : 0.14097511768341064\n",
            "Loss : 0.12061679363250732\n",
            "Loss : 0.05445046350359917\n",
            "Loss : 0.06792294234037399\n",
            "Loss : 0.10104125738143921\n",
            "Loss : 0.05989496409893036\n",
            "Loss : 0.11634471267461777\n",
            "Loss : 0.12398552894592285\n",
            "Loss : 0.12044787406921387\n",
            "Loss : 0.11091186851263046\n",
            "Loss : 0.10364240407943726\n",
            "Loss : 0.08669921010732651\n",
            "Loss : 0.06448443233966827\n",
            "Loss : 0.07764946669340134\n",
            "Loss : 0.05741500481963158\n",
            "Loss : 0.09472491592168808\n",
            "Loss : 0.0789555236697197\n",
            "Loss : 0.07763028889894485\n",
            "Loss : 0.08595389872789383\n",
            "Loss : 0.08991923183202744\n",
            "Loss : 0.13917356729507446\n",
            "Loss : 0.06383958458900452\n",
            "Loss : 0.10422992706298828\n",
            "Loss : 0.1421188861131668\n",
            "Loss : 0.15668265521526337\n",
            "Loss : 0.08803701400756836\n",
            "Loss : 0.06125756725668907\n",
            "Loss : 0.10363895446062088\n",
            "Loss : 0.09647411108016968\n",
            "Loss : 0.11203084141016006\n",
            "Loss : 0.08366253972053528\n",
            "Loss : 0.0761929526925087\n",
            "Loss : 0.05561688542366028\n",
            "Loss : 0.07894859462976456\n",
            "Loss : 0.07752500474452972\n",
            "Loss : 0.055476944893598557\n",
            "Loss : 0.1549798846244812\n",
            "Loss : 0.05434081330895424\n",
            "Loss : 0.10270076990127563\n",
            "Loss : 0.06751202046871185\n",
            "Loss : 0.15937596559524536\n",
            "Loss : 0.08346883207559586\n",
            "Loss : 0.1068868637084961\n",
            "Loss : 0.06265326589345932\n",
            "Loss : 0.11120691150426865\n",
            "Loss : 0.09602103382349014\n",
            "Loss : 0.062398169189691544\n",
            "Loss : 0.08779088407754898\n",
            "Loss : 0.04643234238028526\n",
            "Loss : 0.08017243444919586\n",
            "Loss : 0.10567650943994522\n",
            "Loss : 0.17127461731433868\n",
            "Loss : 0.08090861141681671\n",
            "Loss : 0.07093627005815506\n",
            "Loss : 0.06023184582591057\n",
            "Loss : 0.10349273681640625\n",
            "Loss : 0.10202828049659729\n",
            "Loss : 0.10628342628479004\n",
            "Loss : 0.13250167667865753\n",
            "Loss : 0.12461725622415543\n",
            "Loss : 0.10866159200668335\n",
            "Loss : 0.07204381376504898\n",
            "Loss : 0.12670664489269257\n",
            "Loss : 0.105610691010952\n",
            "Loss : 0.06880544871091843\n",
            "Loss : 0.18636161088943481\n",
            "Loss : 0.11811789125204086\n",
            "Loss : 0.12010827660560608\n",
            "Loss : 0.11482119560241699\n",
            "Loss : 0.10551408678293228\n",
            "Loss : 0.13926003873348236\n",
            "Loss : 0.09662839025259018\n",
            "Loss : 0.0734657570719719\n",
            "Loss : 0.11070996522903442\n",
            "Loss : 0.11408025771379471\n",
            "Loss : 0.05049341544508934\n",
            "Loss : 0.05082330107688904\n",
            "Loss : 0.07553722709417343\n",
            "Loss : 0.11812079697847366\n",
            "Loss : 0.11715059727430344\n",
            "Loss : 0.04743024334311485\n",
            "Loss : 0.09415862709283829\n",
            "Loss : 0.11038003116846085\n",
            "Loss : 0.06294915080070496\n",
            "Loss : 0.10814347118139267\n",
            "Loss : 0.04923020675778389\n",
            "Loss : 0.07159613817930222\n",
            "Loss : 0.062370434403419495\n",
            "Loss : 0.1582029014825821\n",
            "Loss : 0.1351035088300705\n",
            "Loss : 0.07129072397947311\n",
            "Loss : 0.0689907893538475\n",
            "Loss : 0.07707802206277847\n",
            "Loss : 0.08421645313501358\n",
            "Loss : 0.08891060203313828\n",
            "Loss : 0.1060294583439827\n",
            "Loss : 0.07637210935354233\n",
            "Loss : 0.008432149887084961\n",
            "Loss : 0.10398831963539124\n",
            "Loss : 0.03303690627217293\n",
            "Loss : 0.10587284713983536\n",
            "Loss : 0.07047539949417114\n",
            "Loss : 0.08583351224660873\n",
            "Loss : 0.08606207370758057\n",
            "Loss : 0.10827676206827164\n",
            "Loss : 0.08581327646970749\n",
            "Loss : 0.11011651903390884\n",
            "Loss : 0.0755576640367508\n",
            "Loss : 0.10223452001810074\n",
            "Loss : 0.09544841200113297\n",
            "Loss : 0.05605533719062805\n",
            "Loss : 0.12183127552270889\n",
            "Loss : 0.12413167953491211\n",
            "Loss : 0.09658581018447876\n",
            "Loss : 0.10594594478607178\n",
            "Loss : 0.13369660079479218\n",
            "Loss : 0.07016711682081223\n",
            "Loss : 0.1701526641845703\n",
            "Loss : 0.14945675432682037\n",
            "Loss : 0.15513814985752106\n",
            "Epoch 5/5 - Loss: 0.1007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(passages)"
      ],
      "metadata": {
        "id": "FgbmqY0m15GL",
        "outputId": "fecbe289-b003-4b84-db3d-7a4f9380054a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(passage_titles)"
      ],
      "metadata": {
        "id": "vgVojioa16eO",
        "outputId": "8875d9e6-bdd3-4d6b-8e08-2d0874476613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_corpus = {'title': passage_titles, 'text': passages}"
      ],
      "metadata": {
        "id": "tJS9cHgzbz1w"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRContextEncoderTokenizerFast\n",
        "ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTD5Ld_wa1lZ",
        "outputId": "e4938cc1-62a6-4db1-ed6b-701fa9784e4a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_passages = len(chunked_corpus['title'])"
      ],
      "metadata": {
        "id": "S3Jp1-KOblFQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = ctx_tokenizer(\n",
        "    chunked_corpus[\"title\"],\n",
        "    chunked_corpus[\"text\"],\n",
        "    truncation = True,\n",
        "    padding = \"longest\",\n",
        "    return_tensors = \"pt\",\n",
        ")"
      ],
      "metadata": {
        "id": "4DtygO-hcJa9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = outputs[\"input_ids\"]"
      ],
      "metadata": {
        "id": "lrFwGLKYcioG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9_8JxFkcq0S",
        "outputId": "6979e1ec-aa6e-4799-e722-4ab14ad8877f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([464, 258])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cpu\" \n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "else:\n",
        "  print(\"No device is available\")"
      ],
      "metadata": {
        "id": "irbUytEbctDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5693dc9-c207-4715-c68c-8ee8d41e95b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No device is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import DPRContextEncoder\n",
        "# ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "# ctx_encoder = ctx_encoder.to(device=device)"
      ],
      "metadata": {
        "id": "dwFqCgFIdFT9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "metadata": {
        "id": "X9qSNSf4dkhZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "torch.set_grad_enabled(False)\n",
        "t0 = time.time()\n",
        "\n",
        "step = 0\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "num_passages = input_ids.size()[0]\n",
        "num_batches =  math.ceil(num_passages/batch_size)\n",
        "\n",
        "embeds_batches= []\n",
        "for i in range(0, num_passages, batch_size):\n",
        "  if step%100 == 0 and not step ==0:\n",
        "    elapsed = format_time(time.time()-t0)\n",
        "\n",
        "    print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'. format(step, num_batches, elapsed))\n",
        "\n",
        "  batch_ids = input_ids[i:i+16, :]\n",
        "  batch_ids = batch_ids.to(device)\n",
        "\n",
        "  outputs = ctx_encoder(\n",
        "      batch_ids,\n",
        "      return_dict = True,\n",
        "  )\n",
        "\n",
        "  embeddings = outputs[\"pooler_output\"]\n",
        "  embeddings = embeddings.detach().cpu().numpy()\n",
        "\n",
        "  embeds_batches.append(embeddings)\n",
        "  step+= 1\n",
        "  print(step)\n",
        "\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooFO7OZaeASV",
        "outputId": "9a8a0748-3736-44eb-da23-b21ad4202f14"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_passages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KFdcY2JgK9V",
        "outputId": "f6430fd4-0edf-4ed5-bb24-e3b9d71ddfd9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embeddings = np.concatenate(embeds_batches, axis = 0)\n",
        "print('Size of dataset embeddings :', embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WEmtxWIgg6Q",
        "outputId": "b43c6071-c2f0-4100-cc94-702c9be8df0e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of dataset embeddings : (464, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0owKqWM8g-oy",
        "outputId": "65134e2e-b31c-4914-bd7b-a1639143e9f4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "dim = 768\n",
        "m = 128\n",
        "\n",
        "index = faiss.IndexHNSWFlat(dim, m , faiss.METRIC_INNER_PRODUCT)"
      ],
      "metadata": {
        "id": "HYMMqW-XhFns"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t0 = time.time()\n",
        "index.train(embeddings)\n",
        "index.add(embeddings)\n",
        "\n",
        "# print('Done')\n",
        "# print('Adding embeddings to index took', format_time(time.time()-t0))"
      ],
      "metadata": {
        "id": "s71LXAAehhsI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRQuestionEncoder\n",
        "q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "\n",
        "q_encoder = q_encoder.to(device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLJbAaiCh5sG",
        "outputId": "9fa9055c-e4e8-4d7e-f627-cca54410d653"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-multiset-base were not used when initializing DPRQuestionEncoder: ['ctx_encoder.bert_model.encoder.layer.5.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.5.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.9.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.7.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.10.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.key.weight', 'ctx_encoder.bert_model.embeddings.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.5.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.1.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.3.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.5.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.0.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.0.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.7.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.0.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.9.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.9.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.0.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.query.bias', 'ctx_encoder.bert_model.embeddings.token_type_embeddings.weight', 'ctx_encoder.bert_model.encoder.layer.8.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.0.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.5.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.6.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.embeddings.position_embeddings.weight', 'ctx_encoder.bert_model.encoder.layer.5.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.7.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.3.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.2.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.10.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.3.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.5.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.8.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.8.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.3.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.4.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.8.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.3.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.6.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.2.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.2.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.4.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.1.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.7.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.4.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.11.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.8.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.dense.weight', 'ctx_encoder.bert_model.embeddings.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.7.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.9.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.output.LayerNorm.bias', 'ctx_encoder.bert_model.embeddings.word_embeddings.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.4.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.dense.weight']\n",
            "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DPRQuestionEncoder were not initialized from the model checkpoint at facebook/dpr-ctx_encoder-multiset-base and are newly initialized: ['bert_model.encoder.layer.8.output.dense.bias', 'bert_model.encoder.layer.8.attention.self.key.weight', 'bert_model.encoder.layer.9.intermediate.dense.bias', 'bert_model.encoder.layer.7.attention.self.query.bias', 'bert_model.embeddings.token_type_embeddings.weight', 'bert_model.encoder.layer.5.output.LayerNorm.weight', 'bert_model.encoder.layer.9.attention.self.query.bias', 'bert_model.encoder.layer.2.attention.output.dense.bias', 'bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.6.attention.output.dense.weight', 'bert_model.encoder.layer.10.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.self.query.weight', 'bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.attention.output.dense.bias', 'bert_model.encoder.layer.4.attention.self.key.bias', 'bert_model.encoder.layer.6.output.dense.bias', 'bert_model.encoder.layer.8.attention.self.value.weight', 'bert_model.encoder.layer.1.attention.self.value.weight', 'bert_model.encoder.layer.5.output.dense.weight', 'bert_model.encoder.layer.8.output.dense.weight', 'bert_model.encoder.layer.6.attention.self.query.weight', 'bert_model.encoder.layer.3.attention.self.value.weight', 'bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.self.key.bias', 'bert_model.encoder.layer.9.output.LayerNorm.weight', 'bert_model.encoder.layer.7.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.self.query.bias', 'bert_model.encoder.layer.4.output.dense.weight', 'bert_model.encoder.layer.10.attention.self.value.weight', 'bert_model.embeddings.LayerNorm.bias', 'bert_model.encoder.layer.11.intermediate.dense.weight', 'bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.5.intermediate.dense.weight', 'bert_model.encoder.layer.4.attention.output.dense.bias', 'bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.1.output.LayerNorm.bias', 'bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.9.attention.self.query.weight', 'bert_model.encoder.layer.3.attention.self.key.bias', 'bert_model.encoder.layer.10.output.dense.weight', 'bert_model.encoder.layer.6.output.LayerNorm.bias', 'bert_model.encoder.layer.10.attention.output.dense.weight', 'bert_model.encoder.layer.9.attention.self.value.weight', 'bert_model.encoder.layer.6.attention.self.key.bias', 'bert_model.encoder.layer.7.output.dense.weight', 'bert_model.encoder.layer.0.attention.self.key.weight', 'bert_model.encoder.layer.8.attention.self.key.bias', 'bert_model.encoder.layer.2.intermediate.dense.weight', 'bert_model.encoder.layer.1.attention.self.query.bias', 'bert_model.encoder.layer.11.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.self.value.weight', 'bert_model.encoder.layer.5.attention.output.dense.bias', 'bert_model.encoder.layer.10.output.LayerNorm.bias', 'bert_model.encoder.layer.4.output.dense.bias', 'bert_model.encoder.layer.8.output.LayerNorm.weight', 'bert_model.encoder.layer.1.attention.output.dense.bias', 'bert_model.encoder.layer.2.attention.output.dense.weight', 'bert_model.encoder.layer.2.attention.self.query.weight', 'bert_model.encoder.layer.8.attention.self.query.bias', 'bert_model.encoder.layer.1.attention.output.dense.weight', 'bert_model.encoder.layer.11.output.dense.weight', 'bert_model.encoder.layer.1.attention.self.value.bias', 'bert_model.encoder.layer.3.intermediate.dense.weight', 'bert_model.encoder.layer.4.output.LayerNorm.bias', 'bert_model.encoder.layer.10.intermediate.dense.weight', 'bert_model.encoder.layer.11.attention.self.value.weight', 'bert_model.encoder.layer.0.output.dense.bias', 'bert_model.encoder.layer.3.attention.self.value.bias', 'bert_model.encoder.layer.7.intermediate.dense.bias', 'bert_model.encoder.layer.6.attention.self.value.weight', 'bert_model.encoder.layer.8.output.LayerNorm.bias', 'bert_model.encoder.layer.9.attention.output.dense.bias', 'bert_model.encoder.layer.4.attention.self.value.weight', 'bert_model.encoder.layer.5.attention.self.key.bias', 'bert_model.encoder.layer.0.attention.self.value.bias', 'bert_model.encoder.layer.1.attention.self.query.weight', 'bert_model.encoder.layer.3.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.self.value.bias', 'bert_model.encoder.layer.10.attention.self.query.bias', 'bert_model.encoder.layer.0.attention.self.key.bias', 'bert_model.encoder.layer.2.output.dense.weight', 'bert_model.encoder.layer.0.attention.output.dense.weight', 'bert_model.encoder.layer.9.attention.output.dense.weight', 'bert_model.encoder.layer.11.attention.output.dense.bias', 'bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.1.output.dense.weight', 'bert_model.encoder.layer.5.output.LayerNorm.bias', 'bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.10.output.dense.bias', 'bert_model.encoder.layer.9.attention.self.key.bias', 'bert_model.encoder.layer.7.intermediate.dense.weight', 'bert_model.encoder.layer.4.attention.self.query.weight', 'bert_model.encoder.layer.6.attention.self.query.bias', 'bert_model.encoder.layer.0.attention.output.dense.bias', 'bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.6.intermediate.dense.bias', 'bert_model.encoder.layer.5.attention.self.query.weight', 'bert_model.encoder.layer.7.output.LayerNorm.bias', 'bert_model.encoder.layer.8.intermediate.dense.bias', 'bert_model.embeddings.word_embeddings.weight', 'bert_model.encoder.layer.11.intermediate.dense.bias', 'bert_model.encoder.layer.3.intermediate.dense.bias', 'bert_model.encoder.layer.6.output.dense.weight', 'bert_model.encoder.layer.7.attention.output.dense.weight', 'bert_model.encoder.layer.1.attention.self.key.weight', 'bert_model.encoder.layer.8.attention.output.dense.weight', 'bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.0.intermediate.dense.bias', 'bert_model.encoder.layer.5.attention.self.value.weight', 'bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.5.attention.self.key.weight', 'bert_model.encoder.layer.6.attention.self.value.bias', 'bert_model.encoder.layer.9.output.dense.weight', 'bert_model.encoder.layer.11.attention.self.query.weight', 'bert_model.encoder.layer.0.intermediate.dense.weight', 'bert_model.encoder.layer.1.attention.self.key.bias', 'bert_model.encoder.layer.8.intermediate.dense.weight', 'bert_model.encoder.layer.10.attention.self.key.weight', 'bert_model.encoder.layer.4.intermediate.dense.weight', 'bert_model.encoder.layer.2.output.LayerNorm.bias', 'bert_model.encoder.layer.8.attention.output.dense.bias', 'bert_model.encoder.layer.1.output.LayerNorm.weight', 'bert_model.encoder.layer.3.output.LayerNorm.bias', 'bert_model.encoder.layer.0.attention.self.query.weight', 'bert_model.encoder.layer.3.attention.self.query.bias', 'bert_model.encoder.layer.1.intermediate.dense.bias', 'bert_model.encoder.layer.6.attention.output.dense.bias', 'bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.self.query.bias', 'bert_model.embeddings.LayerNorm.weight', 'bert_model.encoder.layer.4.intermediate.dense.bias', 'bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.self.key.bias', 'bert_model.encoder.layer.2.attention.self.key.weight', 'bert_model.encoder.layer.4.attention.self.value.bias', 'bert_model.encoder.layer.0.output.LayerNorm.bias', 'bert_model.encoder.layer.4.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.self.query.weight', 'bert_model.encoder.layer.7.attention.self.key.bias', 'bert_model.encoder.layer.0.output.dense.weight', 'bert_model.encoder.layer.8.attention.self.value.bias', 'bert_model.encoder.layer.2.attention.self.value.weight', 'bert_model.encoder.layer.5.attention.self.value.bias', 'bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.output.dense.weight', 'bert_model.encoder.layer.3.output.dense.weight', 'bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.2.attention.self.query.bias', 'bert_model.encoder.layer.7.output.LayerNorm.weight', 'bert_model.encoder.layer.4.attention.self.query.bias', 'bert_model.encoder.layer.7.output.dense.bias', 'bert_model.encoder.layer.3.attention.output.dense.bias', 'bert_model.encoder.layer.0.output.LayerNorm.weight', 'bert_model.embeddings.position_embeddings.weight', 'bert_model.encoder.layer.9.attention.self.key.weight', 'bert_model.encoder.layer.11.output.dense.bias', 'bert_model.encoder.layer.2.attention.self.key.bias', 'bert_model.encoder.layer.2.output.dense.bias', 'bert_model.encoder.layer.11.attention.self.key.weight', 'bert_model.encoder.layer.1.intermediate.dense.weight', 'bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.output.dense.bias', 'bert_model.encoder.layer.9.attention.self.value.bias', 'bert_model.encoder.layer.10.intermediate.dense.bias', 'bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.2.intermediate.dense.bias', 'bert_model.encoder.layer.6.attention.self.key.weight', 'bert_model.encoder.layer.2.output.LayerNorm.weight', 'bert_model.encoder.layer.7.attention.self.query.weight', 'bert_model.encoder.layer.1.output.dense.bias', 'bert_model.encoder.layer.11.output.LayerNorm.bias', 'bert_model.encoder.layer.4.attention.output.dense.weight', 'bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.self.key.weight', 'bert_model.encoder.layer.11.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.output.dense.weight', 'bert_model.encoder.layer.9.output.LayerNorm.bias', 'bert_model.encoder.layer.5.intermediate.dense.bias', 'bert_model.encoder.layer.2.attention.self.value.bias', 'bert_model.encoder.layer.5.output.dense.bias', 'bert_model.encoder.layer.5.attention.output.dense.weight', 'bert_model.encoder.layer.6.output.LayerNorm.weight', 'bert_model.encoder.layer.5.attention.self.query.bias', 'bert_model.encoder.layer.9.intermediate.dense.weight', 'bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.9.output.dense.bias', 'bert_model.encoder.layer.8.attention.self.query.weight', 'bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.attention.self.key.weight', 'bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.7.attention.self.value.weight', 'bert_model.encoder.layer.6.intermediate.dense.weight', 'bert_model.encoder.layer.4.attention.self.key.weight', 'bert_model.encoder.layer.3.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRQuestionEncoderTokenizerFast\n",
        "\n",
        "q_tokenizer = DPRQuestionEncoderTokenizerFast.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "# q_encoder = q_encoder.to(device)"
      ],
      "metadata": {
        "id": "UT6nVaEtiZE9"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "question = \"Does the ACIP recommend one dose GARDASIL 9?\"\n",
        "\n",
        "# # Convert the question to lowercase\n",
        "# question = question.lower()\n",
        "\n",
        "# # Remove punctuation\n",
        "# question = re.sub(r'[^\\w\\s]', '', question)\n",
        "\n",
        "# # Remove extra whitespaces\n",
        "# question = re.sub(r'\\s+', ' ', question).strip()\n"
      ],
      "metadata": {
        "id": "5qizAbo5XztQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = q_tokenizer.encode(question, return_tensors = \"pt\")\n",
        "input_ids = input_ids.to(device)\n",
        "outputs = q_encoder(input_ids)\n",
        "q_embed = outputs['pooler_output']\n",
        "\n",
        "q_embed = q_embed.cpu().numpy()\n",
        "\n",
        "print(\"Query Embedding:\", q_embed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waetAB16iyHY",
        "outputId": "f6b116d1-6b03-4618-ec5b-d14ceeaae2bc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Embedding: (1, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D, I = index.search(q_embed, k= 10)\n",
        "print(\"Closest matching indices:\", I)\n",
        "\n",
        "print(\"Inner Products:\", D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIdllNOYjZk6",
        "outputId": "c32abfbb-ddc8-44fe-bae5-952c93897b3f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest matching indices: [[153 169 125 113 152 150  91  81 142 108]]\n",
            "Inner Products: [[53.995304 52.564667 43.46164  42.97676  42.14527  41.92007  40.322533\n",
            "  39.053566 38.7771   38.732864]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap \n",
        "retrieved_passages = []\n",
        "retrieved_indices = []\n",
        "wrapper = textwrap.TextWrapper(width = 80)\n",
        "for i in I[0]:\n",
        "  print('Index:', i)\n",
        "  title = chunked_corpus['title'][i]\n",
        "  passage = chunked_corpus['text'][i]\n",
        "\n",
        "  retrieved_passages.append(passage)\n",
        "  retrieved_indices.append(i)\n",
        "\n",
        "  print('Article Title:' , title, '\\n')\n",
        "  print('Passage:')\n",
        "\n",
        "  print(wrapper.fill(passage))\n",
        "  print('')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVm0K4KRjxs-",
        "outputId": "3bda1c31-7f03-4f7b-fb93-bad54d717bf6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 153\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "pcr–negative relevant hpv types 1 month dose 3 month 7§ p articipants enrolled\n",
            "sites 18 countries median duration followup 40 months† v accination also\n",
            "recommended age 26 years men sex men immunocompromised persons including hiv\n",
            "infection vaccinated previouslymorbidity mortality weekly reportmmwr march 27\n",
            "2015 v ol 64 11 303administration 2vhpv 4vhpv 9vhpv administered 3dose schedule\n",
            "second dose admin istered least 1 2 months first dose third dose least 6 months\n",
            "first dose§ 1 vaccine\n",
            "\n",
            "Index: 169\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "ty colposcopy cervical pathology american society clinical pathology screening\n",
            "guidelines prevention early detection cervical cancer j low genit ract dis\n",
            "201216175–204 20 oyer va us preventive services task force screening cervical\n",
            "cancer us preventive services task force recommendation statement ann intern med\n",
            "2012156880–91 w312morbidity mortality weekly reportmmwr march 27 2015 v ol 64 11\n",
            "305these revised recommendations advisory committee immunization practices\n",
            "update recommendations published mmwr 1994 1 include updated information two\n",
            "currently available vaccines vaccine safety\n",
            "\n",
            "Index: 125\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "reportduring june–august 2014 41 probable 14 laboratorycon firmed cases\n",
            "pneumoniae associated single longterm care facility seven patients died facility\n",
            "closed new admissions prolonged period delayed recognition outbreak etiologic\n",
            "agent prolonged transmission period delayed effective interventionswhat\n",
            "implications public health practicelongterm care facilities consider pneumoniae\n",
            "respiratory illness outbreaks facilities need alert outbreaks plan prompt\n",
            "diagnostic testing isolation cohorting ill residents screening staff members\n",
            "illness\n",
            "\n",
            "Index: 113\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "mographic information gathered affected patient table specimens sent nebraska\n",
            "public health laboratory nphl initially cdc cdc multiplex realtime pcr testing\n",
            "performed pneumoniae chlamydophila pneumoniae legionella species human nucleic\n",
            "acid control 1after likely etiologic agent identified pneumoniae case definition\n",
            "modified probable case defined acute respiratory illness either fever ≥1004°f\n",
            "≥380°c pneumonia diagnosed radiograph person epidemiologic link ie resident\n",
            "staff member staff family member visitor confirmed case define\n",
            "\n",
            "Index: 152\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "830antihpv 16 4032 100 3131 4062 100 3157antihpv 18 4539 998 805 4541 997\n",
            "679abbreviations clia competitive luminex immunoassay mmu millimerck unitssource\n",
            "joura ea giuliano ar iversen oe et al 9valent hpv vaccine infection\n",
            "intraepithelial neoplasia women supplementary appendix n engl j med\n",
            "2015372711–23 noninferiority criterion gmts met four hpv types p0001† f emales\n",
            "received 3 vaccinations within 1 year enrollment major deviations study protocol\n",
            "naïve polymerase chain reaction pcr negative seronegative relevant hpv types\n",
            "dose 1 remaine\n",
            "\n",
            "Index: 150\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "confidence interval ≥cin2 cervical intraepithelial neoplasia grade 2 3\n",
            "adenocarcinoma situ vain23 vaginal intraepithelial neoplasia grade 2 3 vin23\n",
            "vulvar intraepithelial neoplasia grade 2 3sources package insert available\n",
            "httpwwwfdagovdownloadsbiologicsbloodvaccinesvaccinesapprovedproductsucm426457pdf\n",
            "joura ea giuliano ar iversen oe et al 9valent hpv vaccine infection\n",
            "intraepithelial neoplasia women n engl j med 2015372711–23 f emales received 3\n",
            "vaccinations within 1 year enrollment major deviations study protocol naïve\n",
            "polymerase chain reaction pcr negative seronegative\n",
            "\n",
            "Index: 91\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "measured among reported physically active result reinforces importance smoking\n",
            "cessation copd patients health care providers play critical role motivating\n",
            "assisting patients including copd smoking cessation information health care\n",
            "providers helping patients quit smoking available online¶ quitting resources\n",
            "patients also available physically active associated greater likelihood activity\n",
            "limitation measures among persons copd association might indicate copd affects\n",
            "patients’ ability physically active physically active might also reinfor\n",
            "\n",
            "Index: 81\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "quipment 187 versus 49 unable work 204 versus 48 statespecific prevalence copd\n",
            "ranged 36 puerto rico 40 minnesota south dakota 9 west virginia 94 alabama 96\n",
            "kentucky 103 copd prevalence highest states along ohio lower mississippi rivers\n",
            "figure 1more one third 380 adults copd current smokers activity limitations\n",
            "common among adults copd adults reported copd likely report unable work 243\n",
            "versus 53 adults without copd activity limitation health problems 496 versus 169\n",
            "difficulty walking\n",
            "\n",
            "Index: 142\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "al conjugate vaccine menactra menacwyd tetanus diphtheria acellular pertussis\n",
            "vaccine adacel tdap evaluated gmts noninferior nine hpv vaccine types\n",
            "coadministered group p0001 menactra noninferiority criterion met four serogroups\n",
            "adacel diphtheria tetanus four pertussis antigenssafety evaluated approximately\n",
            "15000 subjects 9vhpv clinical development program approximately 13000 subjects\n",
            "six studies included initial appli cation submitted fda 2 vaccine welltolerated\n",
            "adverse events injection siterelated pain swell ing eryth\n",
            "\n",
            "Index: 108\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "pharyngeal op swabs autopsy specimens patients realtime polymerase chain\n",
            "reaction pcr testing cdc facility closed new admissions 1 month last case\n",
            "droplet precautions implemented ill residents isolated group activities canceled\n",
            "outbreak total 55 persons expe rienced illnesses met case definition 12 hospital\n",
            "ized seven died pcr detected mycoplasma pneumoniae dna 40 specimens pneumoniae\n",
            "consid ered possible cause respiratory illness outbreaks longterm care\n",
            "facilities morbidity mortality respiratory disease outbreaks longterm care\n",
            "facilities\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_indices"
      ],
      "metadata": {
        "id": "O0p611gDZPFG",
        "outputId": "de780321-397c-49dd-ed94-c1404982e210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[153, 169, 125, 113, 152, 150, 91, 81, 142, 108]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(passages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7ektGEImhdQ",
        "outputId": "98deab69-9edc-4f7e-fa6e-64b151859720"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import DPRQuestionEncoder, DPRContextEncoder, DPRQuestionEncoderTokenizerFast, DPRContextEncoderTokenizerFast\n",
        "# import torch\n",
        "\n",
        "# def embed_question(question):\n",
        "#     q_encoder_model_name = \"facebook/dpr-question_encoder-single-nq-base\"\n",
        "#     q_tokenizer = DPRQuestionEncoderTokenizerFast.from_pretrained(q_encoder_model_name)\n",
        "#     q_encoder = DPRQuestionEncoder.from_pretrained(q_encoder_model_name)\n",
        "    \n",
        "#     input_ids = q_tokenizer.encode(question, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "#     input_ids = input_ids.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#         outputs = q_encoder(input_ids=input_ids)\n",
        "    \n",
        "#     embeddings = outputs.pooler_output\n",
        "    \n",
        "#     return embeddings\n",
        "\n",
        "# def embed_passage(passage):\n",
        "#     ctx_encoder_model_name = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
        "#     ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(ctx_encoder_model_name)\n",
        "#     ctx_encoder = DPRContextEncoder.from_pretrained(ctx_encoder_model_name)\n",
        "    \n",
        "#     input_ids = ctx_tokenizer.encode(passage, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "#     input_ids = input_ids.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#         outputs = ctx_encoder(input_ids=input_ids)\n",
        "    \n",
        "#     embeddings = outputs.pooler_output\n",
        "    \n",
        "#     return embeddings\n"
      ],
      "metadata": {
        "id": "CuHB9kfrm23w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings = embed_passage(passages[0])"
      ],
      "metadata": {
        "id": "W2H7ptSpm5lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans = is_relevant(question, passages[0])"
      ],
      "metadata": {
        "id": "IVHwTfYJnVBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positive_passages = []\n",
        "# negative_passages = []\n",
        "# question = \"Does the ACIP recommend one dose GARDASIL 9?\"\n",
        "# question_embedding = embed_question(question)\n",
        "# for passage in passages:\n",
        "#   if is_relevant(question_embedding, passage) == True:\n",
        "#     positive_passages.append(passage)\n",
        "#   else :\n",
        "#     negative_passages.append(passage)\n",
        "\n"
      ],
      "metadata": {
        "id": "zAzJp06OniWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# # positive_passages = [\"positive passage 1\", \"positive passage 2\", \"positive passage 3\"]\n",
        "# # negative_passages = [\"negative passage 1\", \"negative passage 2\", \"negative passage 3\", \"negative passage 4\"]\n",
        "\n",
        "# dataset = []\n",
        "\n",
        "# for positive_passage in positive_passages:\n",
        "#     # Randomly select a subset of negative passages\n",
        "#     negative_subset = random.sample(negative_passages, k=3)\n",
        "    \n",
        "#     # Create a dictionary with positive and negative passages\n",
        "#     example = {\n",
        "#         \"positive_passages\": positive_passage,\n",
        "#         \"negative_passages\": negative_subset\n",
        "#     }\n",
        "    \n",
        "#     # Add the example to the dataset\n",
        "#     dataset.append(example)\n"
      ],
      "metadata": {
        "id": "lrMgqOvt3N-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "output_dir = \"path_to_save_model\"\n",
        "ctx_encoder.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "4zWATyIqzzAz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "zWAQ522XbTlz",
        "outputId": "2506b934-4520-461b-be82-bfe89af5ceb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "id": "1kXS_9dNaYNb",
        "outputId": "fb8d2572-bb7c-49be-a911-174cad6af431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "IxWFatg6aslU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487530ce-134e-4627-8c9e-c7c8513dcb9b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(chunked_corpus)\n",
        "custom_dataset = Dataset.from_pandas(df)\n",
        "print(custom_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4dn_i-Oouy1",
        "outputId": "45fddc25-f286-4268-c772-9480a1792920"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['title', 'text'],\n",
            "    num_rows: 464\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embs = []\n",
        "for i in range(embeddings.shape[0]):\n",
        "  embs.append(embeddings[i,:])"
      ],
      "metadata": {
        "id": "PtMmMrUqpQgN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset = custom_dataset.add_column(\"embeddings\", embs)\n",
        "custom_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SRhdSnMpxkI",
        "outputId": "e00abba3-1bad-444f-b8ba-181f6f4a5dc8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['title', 'text', 'embeddings'],\n",
              "    num_rows: 464\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.IndexHNSWFlat(dim, m, faiss.METRIC_INNER_PRODUCT)\n",
        "custom_dataset.add_faiss_index(column = \"embeddings\", index_name = \"embeddings\", custom_index=index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "400cc4310e6d4f988fc0f9d935399c4f",
            "186f9ea36c944c478317245d56cea06a",
            "22c4d06835df40158fc65289ff04085d",
            "b3dc18e401f84c7591c9f991b16e4a17",
            "90471e1b6a084f539817d369e6b8db06",
            "e72619f3c67749d09fee1b476119c7a1",
            "09916226602e4001833b0c8603699c63",
            "4e4092479eff4b80a96a693167cbd213",
            "0f4657f534dd4c62aed2f65af6003c11",
            "ca2f304701cf4f689553295634cd7e3c",
            "447f50d4fdba4925af8363e7e08a1ec6"
          ]
        },
        "id": "TYFFCgpRp7hc",
        "outputId": "80ced359-a973-44d1-9e86-17db74addf0d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "400cc4310e6d4f988fc0f9d935399c4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['title', 'text', 'embeddings'],\n",
              "    num_rows: 464\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JOIYN70F9_3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RagRetriever"
      ],
      "metadata": {
        "id": "tfyMjYH9rXxF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade datasets\n",
        "\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install faiss\n",
        "retriever = RagRetriever.from_pretrained(\n",
        "    \"facebook/rag-sequence-nq\",\n",
        "    use_dummy_dataset = False,\n",
        "    indexed_dataset = custom_dataset,\n",
        "    index_name = \"embeddings\",\n",
        ")"
      ],
      "metadata": {
        "id": "mF4sMtjR8G8C",
        "outputId": "ee8ea984-34c0-4d4f-8db2-59fda24f8f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-7a71a9bd21a2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install faiss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m retriever = RagRetriever.from_pretrained(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"facebook/rag-sequence-nq\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0muse_dummy_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/rag/retrieval_rag.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"faiss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mRagConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mrag_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: \nRagRetriever requires the 🤗 Datasets library but it was not found in your environment. You can install it with:\n```\npip install datasets\n```\nIn a notebook or a colab, you can install it by executing a cell with\n```\n!pip install datasets\n```\nthen restarting your kernel.\n\nNote that if you have a local folder named `datasets` or a local python file named `datasets.py` in your current\nworking directory, python may try to import this instead of the 🤗 Datasets library. You should rename this folder or\nthat python file if that's the case. Please note that you may need to restart your runtime after installation.\n\nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RagTokenizer\n",
        "tokenizer = RagTokenizer.from_pretrained(\n",
        "    \"facebook/rag-sequence-nq\"\n",
        ")"
      ],
      "metadata": {
        "id": "Fb7dJbZ9sLF4",
        "outputId": "008e4c28-f728-4b38-aa91-7169db2e75d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RagSequenceForGeneration\n",
        "model = RagSequenceForGeneration.from_pretrained(\n",
        "    \"facebook/rag-sequence-nq\",\n",
        "    retriever = retriever\n",
        ")"
      ],
      "metadata": {
        "id": "3NzKyKqe-iyb",
        "outputId": "a9464f5a-eda2-48a8-cc28-6fb0d258e630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/rag-sequence-nq were not used when initializing RagSequenceForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.weight', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RagSequenceForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RagSequenceForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RagSequenceForGeneration were not initialized from the model checkpoint at facebook/rag-sequence-nq and are newly initialized: ['rag.generator.lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\n",
        "len = 4\n",
        "for i in range(4):\n",
        "  context = context + retrieved_passages[i]\n"
      ],
      "metadata": {
        "id": "YdviMYLOiWPE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "id": "g-JAyw7OiiJ9",
        "outputId": "d454c3d7-0f1b-48e5-eeb2-902da6350d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'skinner sr et al efficacy human papillomavirus hpv1618 as04adjuvanted vaccine women aged 15–25 years without serological evidence previous exposure hpv1618 int j cancer 2012131106–16 164 herrero r quint w hildesheim et al reduced prevalence oral human papillomavirus hpv 4 years bivalent hpv vaccination randomized clinical trial costa rica plos one 20138e68329 165 kreimer ar gonzalez p katki ha et al efficacy bivalent hpv 1618 vaccine anal hpv 1618 infection among young women nested analysis within costa rica vaccine rial lancet oncol 201112862–70 166 naud ps rotelimartins cm de carvalint j cancer 2013132198–207 207 markowitz le hariri lin c et al reduction human papillomavirus hpv prevalence among young women following hpv vaccine introduction united states national health nutrition examination surveys 2003–2010 j infect dis 2013208385–93 208 flagg ew schwartz r weinstock h prevalence anogenital warts among participants private health plans united states 2003–2010 potential impact human papillomavirus vaccination j public health 20131031428–35 209 hariri markowitz le dunne ef unger er population impact hpv vaccines summary early evidence j adolesc health 2013 53679–82 210 ali h donovanronic obstructive pulmonary disease — united states 2013anne g wheaton phd1 timothy j cunningham phd1 earl ford md1 janet b croft phd1 author affiliations end textinside296 mycoplasma pneumoniae outbreak longterm care facility — nebraska 2014300 u se 9valent human papillomavirus hpv vaccine updated hpv vaccination recommendations advisory committee immunization practices305 upda ted recommendations use typhoid vaccine — advisory committee immunization practices united states 2015309 announcement310 quickstatscontinuing education examination available httpwwwcdcgovmmwrcmecontedinfohtmlweekly † available httpwed guide help states develop implement tobacco control programs§§ cdc also compiled guide communitybased strategies increase physical activity cdc guide strategies increase physical activity community¶¶ 1division population health national center chronic disease prevention health promotion cdc corresponding author anne g wheaton awheatoncdcgov 7704885362references 1 h eron deaths leading causes 2010 natl vital stat rep 2013 621–96 2 us b urden disease collaborators state us health 19902010 burden diseases injuries risk factors jama 2013310591–608 3 lee pn f ry js systematic review'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Does the ACIP recommend one dose GARDASIL 9?\""
      ],
      "metadata": {
        "id": "C2pzibvvikj-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the inputs\n",
        "# input_dict = tokenizer(question, context, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "LB_anr4biID1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_docs = 5"
      ],
      "metadata": {
        "id": "Cm5uK9BljBF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Reshape input_ids_np to match the expected dimension\n",
        "# input_ids_np = input_ids_np.reshape(1, -1)\n",
        "\n",
        "# # Perform passage retrieval\n",
        "# retrieved_doc_ids = retriever.retrieve(input_ids_np, n_docs=n_docs)\n",
        "\n",
        "# # Get the retrieved documents\n",
        "# retrieved_docs = retriever.batch_retrieve(retrieved_doc_ids)"
      ],
      "metadata": {
        "id": "dnGljDrViyZW"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# t0 = time.time()\n",
        "\n",
        "# question = \"Is GARDASIL 9 recommended for Adults?\"\n",
        "\n",
        "# input_ids = tokenizer.question_encoder(question, return_tensors = \"pt\")[\"input_ids\"]\n",
        "# generated = model.generate(input_ids)\n",
        "\n",
        "# generated_string = tokenizer.batch_decode(generated, skip_special_tokens = True)[0]\n",
        "# print(generated_string)"
      ],
      "metadata": {
        "id": "rxbjW73N-4RD"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "question = \"Does the ACIP recommend one dose GARDASIL 9?\"\n",
        "\n",
        "outputs = tokenizer.question_encoder(question, return_tensors=\"pt\")\n",
        "input_ids = outputs[\"input_ids\"] \n",
        "attention_mask = outputs[\"attention_mask\"] \n",
        "\n",
        "generated = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    num_return_sequences=8,\n",
        "    max_length=50,\n",
        "    temperature=0.8,\n",
        "    num_beams = 5,\n",
        "    min_length=30  # Set the desired minimum length here\n",
        ")\n",
        "generated_strings = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
        "for i, generated_string in enumerate(generated_strings):\n",
        "    print(f\"Generated sequence {i + 1}: {generated_string}\")\n",
        "\n",
        "print(f\"Time taken: {time.time() - t0:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "L7KHy6cEBFrT",
        "outputId": "8abe562f-e470-4b27-ad07-b51af554d31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-eceba44d1522>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Does the ACIP recommend one dose GARDASIL 9?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model"
      ],
      "metadata": {
        "id": "FuASYOyq7_G6",
        "outputId": "79e4725c-98f5-472e-bedb-1f9bb2687df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer"
      ],
      "metadata": {
        "id": "J86sMA-P8BIt",
        "outputId": "d26184a6-02aa-425d-b3e7-4afe93f0672c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5Tokenizer(name_or_path='t5-base', vocab_size=32100, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question"
      ],
      "metadata": {
        "id": "zAqn_JWs9YTK",
        "outputId": "e2986b2c-84bd-4973-8843-453cabaa71d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Does the ACIP recommend one dose GARDASIL 9?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = t5_tokenizer.prepare_seq2seq_batch(question, retrieved_passages, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "TUPL8D4R9baQ",
        "outputId": "424f2082-bbdf-401a-b18c-342b4ce65dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3732: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3606: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = t5_model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n"
      ],
      "metadata": {
        "id": "7vnM8div9lKO",
        "outputId": "1d531bfb-7dd5-44c8-d19f-a0f43dc8c256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers = t5_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "9s0qobPc9siF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate answers\n",
        "outputs = t5_model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],num_beams=10, num_return_sequences=1)\n",
        "\n",
        "# Decode and print the answers\n",
        "for i, output in enumerate(outputs):\n",
        "    answer = t5_tokenizer.decode(output, skip_special_tokens=True)\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "id": "DGZ42H8b9-PO",
        "outputId": "23782853-24ba-4b64-abb8-a45d93b2d1a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: Does the ACIP recommend one dose GARDASIL 9?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate answers from each passage\n",
        "answers = []\n",
        "for passage in retrieved_passages:\n",
        "    # Concatenate the question and passage\n",
        "    input_text = f\"question: {question} context: {passage}\"\n",
        "\n",
        "    # Encode the input text\n",
        "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the answer\n",
        "    output = t5_model.generate(input_ids, num_beams = 5, max_length=50)\n",
        "\n",
        "    # Decode and store the answer\n",
        "    answer = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    answers.append(answer)\n",
        "\n",
        "# Print the generated answers\n",
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")\n"
      ],
      "metadata": {
        "id": "_smBvcVZ_0yD",
        "outputId": "7df2604e-fe4e-4f10-9854-64f320f6ccf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: 2vhpv 4vhpv 9vhpv administered 3dose schedule second dose admin istered least 1 2 months first dose third dose least 6 months first dose 1 vaccine\n",
            "Answer 2: 2012156880–91 w312morbidity mortality weekly reportmmwr march 27 2015 v ol 64 11 305these revised recommendations advisory committee immunization practices update recommendations published mmwr 1994\n",
            "Answer 3: etiologic agent prolonged transmission period delayed effective interventionswhat implications public health practicelongterm care facilities consider pneumoniae respiratory illness outbreaks\n",
            "Answer 4: 1004°f 380°c pneumonia diagnosed radiograph person epidemiologic link ie resident staff member staff family member visitor confirmed case define\n",
            "Answer 5: 18 4539 998 805 4541 997 679abbreviations clia competitive luminex immunoassay mmu millimerck unitssource joura ea giuliano ar i\n",
            "Answer 6: joura ea giuliano ar iversen oe et al 9valent hpv vaccine infection intraepithelial neoplasia women n engl j\n",
            "Answer 7: measured among reported physically active result reinforces importance smoking cessation\n",
            "Answer 8: west virginia 94 alabama 96 kentucky 103 copd prevalence highest states along ohio lower mississippi rivers figure 1more one third 380 adults copd\n",
            "Answer 9: vaccine types coadministered group p0001 menactra noninferiority criterion met four serogroups adacel diphtheria tetanus four per\n",
            "Answer 10: 1 month last case droplet precautions implemented ill residents canceled outbreak total 55 persons expe rienced illnesses met case definition 12 hospital ized seven died pcr detected mycoplasma pneumoniae dna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate answers from each passage\n",
        "answers = []\n",
        "# for passage in retrieved_passages:\n",
        "#     # Concatenate the question and passage\n",
        "input_text = f\"question: {question} context: {retrieved_passages}\"\n",
        "\n",
        "    # Encode the input text\n",
        "input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the answer\n",
        "output = t5_model.generate(input_ids, num_beams = 5, max_length=50)\n",
        "\n",
        "    # Decode and store the answer\n",
        "answer = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "answers.append(answer)\n",
        "\n",
        "# Print the generated answers\n",
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "id": "VHi6GJxSA8tx",
        "outputId": "06f3d024-bf11-4e6a-aff4-d3aae178a1d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: 3 month 7 p articipants enrolled sites 18 countries median duration followup 40 months v accination also recommended age 26 years men sex men immunocompromised persons including hiv infection vac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "id": "xcynwX919vMM",
        "outputId": "a8bc1b61-277f-4ccd-916c-203f5c0ca91b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: acip recommends vaccination men sex men immunocompromised persons including hiv infection age 26 years previously vaccinatedas compendium current recommendations use hpv vaccines information report intended use clinicians vaccination\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is GARDASIL 9 recommended for Adults?"
      ],
      "metadata": {
        "id": "S36eh8o7oqVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "question = \"Is GARDASIL 9 recommended for Adults?\""
      ],
      "metadata": {
        "id": "juCmoGs7oucW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = q_tokenizer.encode(question, return_tensors = \"pt\")\n",
        "input_ids = input_ids.to(device)\n",
        "outputs = q_encoder(input_ids)\n",
        "q_embed = outputs['pooler_output']\n",
        "q_embed = q_embed.cpu().numpy()\n",
        "print(\"Query Embedding:\", q_embed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5ZvTUj-oz_B",
        "outputId": "1a8b7717-1ddc-40e1-cd39-af22179e3cd2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Embedding: (1, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D, I = index.search(q_embed, k= 10)\n",
        "print(\"Closest matching indices:\", I)\n",
        "print(\"Inner Products:\", D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJieFQRQo3BS",
        "outputId": "1ec0b746-3ea3-4818-fb9d-eb7458643d80"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest matching indices: [[153 169 236 125 113 142 152  81 150  91]]\n",
            "Inner Products: [[50.93097  47.885983 44.287144 42.791046 42.30501  41.191277 41.11387\n",
            "  40.902687 40.197937 39.446865]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap \n",
        "retrieved_passages = []\n",
        "retrieved_indices = []\n",
        "wrapper = textwrap.TextWrapper(width = 80)\n",
        "for i in I[0]:\n",
        "  print('Index:', i)\n",
        "  title = chunked_corpus['title'][i]\n",
        "  passage = chunked_corpus['text'][i]\n",
        "  retrieved_passages.append(passage)\n",
        "  retrieved_indices.append(i)\n",
        "  print('Article Title:' , title, '\\n')\n",
        "  print('Passage:')\n",
        "  print(wrapper.fill(passage))\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqCCw4_Vo5Ll",
        "outputId": "e65e50f8-8909-49e9-fd4d-f9f52bc7fafb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 222\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "26 years may vaccinated acip recommends vaccination men sex men\n",
            "immunocompromised persons including hiv infection age 26 years previously\n",
            "vaccinatedas compendium current recommendations use hpv vaccines information\n",
            "report intended use clinicians vaccination providers public health officials\n",
            "immunization program personnel resource acip recommendations reviewed\n",
            "periodically revised indicated new information data become\n",
            "availablerecommendations reports2 mmwr ugust 29 2014 vol 63 5cervical cancer hpv\n",
            "infection also cause anoge\n",
            "\n",
            "Index: 456\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "ican osteopathic association stanley e grogg ulsa oklahoma american pharmacists\n",
            "association stephan l foster pharmd memphis tennessee association immunization\n",
            "managers kelly moore md nashville tennessee association prevention teaching\n",
            "research w paul mckinney md louisville kentucky association state territorial\n",
            "health officials terry dwelle md bismarck north dakota biotechnology industry\n",
            "organization clement lewin phd cambridge massachusetts council state territorial\n",
            "epidemiologists christine hahn md state epidemiologist office epidemiology food\n",
            "protection immunization boise idaho canadian national advisory committee\n",
            "\n",
            "Index: 376\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "hpv4recommendations reports22 mmwr ugust 29 2014 vol 63 5special\n",
            "populationsabnormal pap test known hpv infection anogenital warts hpvassociated\n",
            "lesionshpv vaccination provide protection infection hpv vaccine types already\n",
            "acquired therefore vaccination recommended recommended age females regardless\n",
            "whether abnormal pap test result females males regardless known hpv infection\n",
            "hpvassociated precancer lesions anogenital warts females abnormalities cervical\n",
            "cancer screening likely infected one genital hpv types increasing severity pap\n",
            "test fin\n",
            "\n",
            "Index: 413\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "sco 2000–2009 cancer 20131193539–45 82 gillison ml alemany l snijders pj et al\n",
            "human papillomavirus diseases upper airway head neck cancer respiratory\n",
            "papillomatosis vaccine 201230suppl 5f34–54 83 kreimer ar clifford gm boyle p\n",
            "franceschi human papillomavirus types head neck squamous cell carcinomas\n",
            "worldwide systematic review cancer epidemiol biomarkers prev 200514467–75 84\n",
            "backes dm kurman rj pimenta jm smith js systematic review human papillomavirus\n",
            "prevalence invasive penile cancer cancer causes control 200920449–57 85 wideroff\n",
            "l schottenfeld penile cancer schottenfeld fraumeni j eds cancer epidemiolo\n",
            "\n",
            "Index: 452\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "nta georgiamembers nancy bennett md rochester new york joseph bocchini jr md\n",
            "louisiana state university health sciences center shreveport louisiana douglas\n",
            "camposoutcalt md university arizona college medicine–phoenix phoenix arizona\n",
            "tamera coynebeasley md university north carolina school medicine chapel hill\n",
            "north carolina jeffrey duchin md public health–seattle king county university\n",
            "washington school medicine seattle washington kathleen harriman phd california\n",
            "department public health richmond california lee h harrison md university\n",
            "pittsburgh pittsburgh pennsylvania renée r jenkins md howard university college\n",
            "\n",
            "Index: 224\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "rials postlicensure safety studies monitoring compiles recommendations cdc’s\n",
            "advisory committee immunization practices acip use hpv vaccines 12– 15methodsthe\n",
            "advisory committee immunization practices acip hpv vaccine work group first met\n",
            "february 2004 begin reviewing data related hpv4 since february 2004 work group\n",
            "held multiple teleconferences periodic meetings review published unpublished\n",
            "data hpv2 hpv4 clinical trials including data safety immunogenicity efficacy\n",
            "12–15 data epidemiology natural history hpv sexual behavior vaccine\n",
            "acceptability costeffectiveness hpv vaccination\n",
            "\n",
            "Index: 421\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "ged 16–26 years j infect dis 2009199926–35 110 dias van doren j schlottmann et\n",
            "al optimization validation multiplexed luminex assay quantify antibodies\n",
            "neutralizing epitopes human papillomaviruses 6 11 16 18 clin diagn lab immunol\n",
            "200512959–69 111 opalka lachman ce macmullen sa et al simultaneous quantitation\n",
            "antibodies neutralizing epitopes viruslike particles human papillomavirus types\n",
            "6 11 16 18 multiplexed luminex assay clin diagn lab immunol 200310108–15 112\n",
            "einstein mh baron levin mj et al comparison immunogenicity safety cervarix\n",
            "gardasil human papillomavirus hpv cervical cancer\n",
            "\n",
            "Index: 316\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "ce registries hpv4 classified pregnancy category b basis studies rats showing\n",
            "evidence impaired fertility harm fetus 11a registry females inadvertently\n",
            "vaccinated pregnancy established manufacturer part postlicensure commitment fda\n",
            "142143 2800 females received vaccine within 1 month last menstrual period\n",
            "anytime pregnancy enrolled registry 144 rates spontaneous abortions major birth\n",
            "defects greater comparison unexposed population registry terminated end december\n",
            "2012 concurrence fda reg\n",
            "\n",
            "Index: 245\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "natural history hpv poorly understood including role duration naturally acquired\n",
            "immunity hpv infectionclinical sequelae hpv infectioncancers associated\n",
            "hpvpersistent infection oncogenic hpv types causal role nearly cervical cancers\n",
            "many vulvar vaginal penile recommendations reportsmmwr august 29 2014 vol 63 5\n",
            "5anal oropharyngeal cancers 57 basis data national cancer institute’s\n",
            "surveillance epidemiology end results seer program cdc’s national program cancer\n",
            "registries npcr burden hpvassociated cancers united states estimated 58because\n",
            "\n",
            "Index: 220\n",
            "Article Title: Recommendations of the Advisory Committee on Immunization Practices \n",
            "\n",
            "Passage:\n",
            "emerging zoonotic infectious diseases cdcsummarythis report summarizes\n",
            "epidemiology human papillomavirus hpv associated diseases describes licensed hpv\n",
            "vaccines provides updated data clinical trials postlicensure safety studies\n",
            "compiles recommendations cdc’s advisory committee immunization practices acip\n",
            "use hpv vaccinespersistent infection oncogenic hpv types cause cervical cancer\n",
            "women well anogenital oropharyngeal cancers women men hpv also causes genital\n",
            "warts two hpv vaccines licensed united states composed typespecific hpv l1\n",
            "protein major capsid protein hpv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ok--6qAFpMb2",
        "outputId": "b0231b7a-6a73-46bb-c6bb-506c8c0c2ef6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is GARDASIL 9 recommended for Adults?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate answers from each passage\n",
        "answers = []\n",
        "# for passage in retrieved_passages:\n",
        "#     # Concatenate the question and passage\n",
        "input_text = f\"question: {question} context: {retrieved_passages}\"\n",
        "\n",
        "    # Encode the input text\n",
        "input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the answer\n",
        "output = t5_model.generate(input_ids, num_beams = 10, max_length=50)\n",
        "\n",
        "    # Decode and store the answer\n",
        "answer = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "answers.append(answer)\n",
        "\n",
        "# Print the generated answers\n",
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXhvvSFGpDBQ",
        "outputId": "53f1637d-c065-4eb1-a817-b1c938870253"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: 26 years men sex men immunocompromised persons including hiv infection vaccinated previouslymorbidity mortality weekly reportmmwr march 27 2015 v ol 64 11 303administration 2vhpv 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzzOsOtMpb5c",
        "outputId": "224015af-e3c2-4d20-f4da-cb734f6f27b0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: 26 years men sex men immunocompromised persons including hiv infection vaccinated previouslymorbidity mortality weekly reportmmwr march 27 2015 v ol 64 11 303administration 2vhpv 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What were the past 3 recommendation changes for GARDASIL 9?"
      ],
      "metadata": {
        "id": "lrENScJ2p9IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "question = \"What were the past 3 recommendation changes for GARDASIL 9?\""
      ],
      "metadata": {
        "id": "PcbBIFg2qAvg"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = q_tokenizer.encode(question, return_tensors = \"pt\")\n",
        "input_ids = input_ids.to(device)\n",
        "outputs = q_encoder(input_ids)\n",
        "q_embed = outputs['pooler_output']\n",
        "q_embed = q_embed.cpu().numpy()\n",
        "print(\"Query Embedding:\", q_embed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngr8Id8qqTnl",
        "outputId": "f3f51d66-5a73-40da-d08c-3e350a2fdd0d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Embedding: (1, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D, I = index.search(q_embed, k= 10)\n",
        "print(\"Closest matching indices:\", I)\n",
        "print(\"Inner Products:\", D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJZiQw2JqW2n",
        "outputId": "bb5ec074-a178-4b00-d436-a46acc33bb46"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest matching indices: [[153 169  91 113  81 152 125 108 150  99]]\n",
            "Inner Products: [[51.398293 48.909416 42.26519  41.768326 40.34675  39.81498  39.358776\n",
            "  38.60151  38.569244 37.1046  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap \n",
        "retrieved_passages = []\n",
        "retrieved_indices = []\n",
        "wrapper = textwrap.TextWrapper(width = 80)\n",
        "for i in I[0]:\n",
        "  print('Index:', i)\n",
        "  title = chunked_corpus['title'][i]\n",
        "  passage = chunked_corpus['text'][i]\n",
        "  retrieved_passages.append(passage)\n",
        "  retrieved_indices.append(i)\n",
        "  print('Article Title:' , title, '\\n')\n",
        "  print('Passage:')\n",
        "  print(wrapper.fill(passage))\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_s-_oRSqZMm",
        "outputId": "1af42668-4d77-47ed-8dfc-9cbc80060233"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 153\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "pcr–negative relevant hpv types 1 month dose 3 month 7§ p articipants enrolled\n",
            "sites 18 countries median duration followup 40 months† v accination also\n",
            "recommended age 26 years men sex men immunocompromised persons including hiv\n",
            "infection vaccinated previouslymorbidity mortality weekly reportmmwr march 27\n",
            "2015 v ol 64 11 303administration 2vhpv 4vhpv 9vhpv administered 3dose schedule\n",
            "second dose admin istered least 1 2 months first dose third dose least 6 months\n",
            "first dose§ 1 vaccine\n",
            "\n",
            "Index: 169\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "ty colposcopy cervical pathology american society clinical pathology screening\n",
            "guidelines prevention early detection cervical cancer j low genit ract dis\n",
            "201216175–204 20 oyer va us preventive services task force screening cervical\n",
            "cancer us preventive services task force recommendation statement ann intern med\n",
            "2012156880–91 w312morbidity mortality weekly reportmmwr march 27 2015 v ol 64 11\n",
            "305these revised recommendations advisory committee immunization practices\n",
            "update recommendations published mmwr 1994 1 include updated information two\n",
            "currently available vaccines vaccine safety\n",
            "\n",
            "Index: 91\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "measured among reported physically active result reinforces importance smoking\n",
            "cessation copd patients health care providers play critical role motivating\n",
            "assisting patients including copd smoking cessation information health care\n",
            "providers helping patients quit smoking available online¶ quitting resources\n",
            "patients also available physically active associated greater likelihood activity\n",
            "limitation measures among persons copd association might indicate copd affects\n",
            "patients’ ability physically active physically active might also reinfor\n",
            "\n",
            "Index: 113\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "mographic information gathered affected patient table specimens sent nebraska\n",
            "public health laboratory nphl initially cdc cdc multiplex realtime pcr testing\n",
            "performed pneumoniae chlamydophila pneumoniae legionella species human nucleic\n",
            "acid control 1after likely etiologic agent identified pneumoniae case definition\n",
            "modified probable case defined acute respiratory illness either fever ≥1004°f\n",
            "≥380°c pneumonia diagnosed radiograph person epidemiologic link ie resident\n",
            "staff member staff family member visitor confirmed case define\n",
            "\n",
            "Index: 81\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "quipment 187 versus 49 unable work 204 versus 48 statespecific prevalence copd\n",
            "ranged 36 puerto rico 40 minnesota south dakota 9 west virginia 94 alabama 96\n",
            "kentucky 103 copd prevalence highest states along ohio lower mississippi rivers\n",
            "figure 1more one third 380 adults copd current smokers activity limitations\n",
            "common among adults copd adults reported copd likely report unable work 243\n",
            "versus 53 adults without copd activity limitation health problems 496 versus 169\n",
            "difficulty walking\n",
            "\n",
            "Index: 152\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "830antihpv 16 4032 100 3131 4062 100 3157antihpv 18 4539 998 805 4541 997\n",
            "679abbreviations clia competitive luminex immunoassay mmu millimerck unitssource\n",
            "joura ea giuliano ar iversen oe et al 9valent hpv vaccine infection\n",
            "intraepithelial neoplasia women supplementary appendix n engl j med\n",
            "2015372711–23 noninferiority criterion gmts met four hpv types p0001† f emales\n",
            "received 3 vaccinations within 1 year enrollment major deviations study protocol\n",
            "naïve polymerase chain reaction pcr negative seronegative relevant hpv types\n",
            "dose 1 remaine\n",
            "\n",
            "Index: 125\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "reportduring june–august 2014 41 probable 14 laboratorycon firmed cases\n",
            "pneumoniae associated single longterm care facility seven patients died facility\n",
            "closed new admissions prolonged period delayed recognition outbreak etiologic\n",
            "agent prolonged transmission period delayed effective interventionswhat\n",
            "implications public health practicelongterm care facilities consider pneumoniae\n",
            "respiratory illness outbreaks facilities need alert outbreaks plan prompt\n",
            "diagnostic testing isolation cohorting ill residents screening staff members\n",
            "illness\n",
            "\n",
            "Index: 108\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "pharyngeal op swabs autopsy specimens patients realtime polymerase chain\n",
            "reaction pcr testing cdc facility closed new admissions 1 month last case\n",
            "droplet precautions implemented ill residents isolated group activities canceled\n",
            "outbreak total 55 persons expe rienced illnesses met case definition 12 hospital\n",
            "ized seven died pcr detected mycoplasma pneumoniae dna 40 specimens pneumoniae\n",
            "consid ered possible cause respiratory illness outbreaks longterm care\n",
            "facilities morbidity mortality respiratory disease outbreaks longterm care\n",
            "facilities\n",
            "\n",
            "Index: 150\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "confidence interval ≥cin2 cervical intraepithelial neoplasia grade 2 3\n",
            "adenocarcinoma situ vain23 vaginal intraepithelial neoplasia grade 2 3 vin23\n",
            "vulvar intraepithelial neoplasia grade 2 3sources package insert available\n",
            "httpwwwfdagovdownloadsbiologicsbloodvaccinesvaccinesapprovedproductsucm426457pdf\n",
            "joura ea giuliano ar iversen oe et al 9valent hpv vaccine infection\n",
            "intraepithelial neoplasia women n engl j med 2015372711–23 f emales received 3\n",
            "vaccinations within 1 year enrollment major deviations study protocol naïve\n",
            "polymerase chain reaction pcr negative seronegative\n",
            "\n",
            "Index: 99\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "ed guide help states develop implement tobacco control programs§§ cdc also\n",
            "compiled guide communitybased strategies increase physical activity cdc guide\n",
            "strategies increase physical activity community¶¶ 1division population health\n",
            "national center chronic disease prevention health promotion cdc corresponding\n",
            "author anne g wheaton awheatoncdcgov 7704885362references 1 h eron deaths\n",
            "leading causes 2010 natl vital stat rep 2013 621–96 2 us b urden disease\n",
            "collaborators state us health 19902010 burden diseases injuries risk factors\n",
            "jama 2013310591–608 3 lee pn f ry js systematic review\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1iKF-GuQqnrc",
        "outputId": "2f816316-0dd6-4fde-9ae3-2a5e65ecf818"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What were the past 3 recommendation changes for GARDASIL 9?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "# for passage in retrieved_passages:\n",
        "#     # Concatenate the question and passage\n",
        "input_text = f\"question: {question} context: {retrieved_passages}\"\n",
        "\n",
        "    # Encode the input text\n",
        "input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the answer\n",
        "output = t5_model.generate(input_ids, num_beams = 10, max_length=50)\n",
        "\n",
        "    # Decode and store the answer\n",
        "answer = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "answers.append(answer)\n",
        "\n",
        "# Print the generated answers\n",
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rehWfK7hqkZB",
        "outputId": "2cc6a0ce-e092-4c1f-c0f2-d9a7e56727d2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: west virginia 94 alabama 96 kentucky 103 copd prevalence highest states along ohio lower mississippi rivers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate answers from each passage\n",
        "answers = []\n",
        "for passage in retrieved_passages:\n",
        "    # Concatenate the question and passage\n",
        "    input_text = f\"question: {question} context: {passage}\"\n",
        "\n",
        "    # Encode the input text\n",
        "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the answer\n",
        "    output = t5_model.generate(input_ids, num_beams = 5, max_length=50)\n",
        "\n",
        "    # Decode and store the answer\n",
        "    answer = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    answers.append(answer)\n",
        "\n",
        "# Print the generated answers\n",
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W47RJ58_rFGg",
        "outputId": "bd0c7730-129e-4ac4-a82a-e3703bf69882"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: 2vhpv 4vhpv 9vhpv administered 3dose schedule second dose second dose third dose least 6 months first dose 1 vaccine\n",
            "Answer 2: these revised recommendations advisory committee immunization practices update recommendations published mmwr 1994 1 include updated information two currently available vaccines\n",
            "Answer 3: \n",
            "Answer 4: either fever 1004°f 380°c pneumonia diagnosed radiograph person epidemiologic link ie resident staff member staff family member visitor confirmed case define\n",
            "Answer 5: west virginia 94 alabama 96 kentucky 103\n",
            "Answer 6: supplementary appendix n engl j med 2015372711–23 noninferiority criterion gmts met four hpv types p0001 f\n",
            "Answer 7: closed new admissions\n",
            "Answer 8: 1 month last case droplet precautions implemented ill residents isolated group activities canceled outbreak total 55 persons expe rienced illnesses met case definition 12 hospital ized seven died pcr detected mycoplasma pneumoniae\n",
            "Answer 9: major deviations study protocol nave polymerase chain reaction pcr negative seronegative\n",
            "Answer 10: lee pn f ry js systematic review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# When did the GARDASIL 9 recommendations change?"
      ],
      "metadata": {
        "id": "wHzIzsM5rjkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "question = \"When did the GARDASIL 9 recommendations change?\""
      ],
      "metadata": {
        "id": "ZM4SLN8hrnOW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = q_tokenizer.encode(question, return_tensors = \"pt\")\n",
        "input_ids = input_ids.to(device)\n",
        "outputs = q_encoder(input_ids)\n",
        "q_embed = outputs['pooler_output']\n",
        "q_embed = q_embed.cpu().numpy()\n",
        "print(\"Query Embedding:\", q_embed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S-MnlQxrvDq",
        "outputId": "93ae4891-f2a3-4c4b-fcda-aa98e9579f80"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Embedding: (1, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D, I = index.search(q_embed, k= 10)\n",
        "print(\"Closest matching indices:\", I)\n",
        "print(\"Inner Products:\", D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9iYDx9irxCN",
        "outputId": "155c3932-c079-4b32-bb43-663af3b83969"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest matching indices: [[153 169 113 125 150  91 152  81 108  99]]\n",
            "Inner Products: [[54.39225  52.55819  46.17887  42.71117  42.48359  42.055244 41.796356\n",
            "  41.5521   41.02681  40.584393]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap \n",
        "retrieved_passages = []\n",
        "retrieved_indices = []\n",
        "wrapper = textwrap.TextWrapper(width = 80)\n",
        "for i in I[0]:\n",
        "  print('Index:', i)\n",
        "  title = chunked_corpus['title'][i]\n",
        "  passage = chunked_corpus['text'][i]\n",
        "  retrieved_passages.append(passage)\n",
        "  retrieved_indices.append(i)\n",
        "  print('Article Title:' , title, '\\n')\n",
        "  print('Passage:')\n",
        "  print(wrapper.fill(passage))\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8QgHSb4r0o-",
        "outputId": "3e4c3626-b46b-4761-ccb4-b1f0fb8623a4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 153\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "pcr–negative relevant hpv types 1 month dose 3 month 7§ p articipants enrolled\n",
            "sites 18 countries median duration followup 40 months† v accination also\n",
            "recommended age 26 years men sex men immunocompromised persons including hiv\n",
            "infection vaccinated previouslymorbidity mortality weekly reportmmwr march 27\n",
            "2015 v ol 64 11 303administration 2vhpv 4vhpv 9vhpv administered 3dose schedule\n",
            "second dose admin istered least 1 2 months first dose third dose least 6 months\n",
            "first dose§ 1 vaccine\n",
            "\n",
            "Index: 169\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "ty colposcopy cervical pathology american society clinical pathology screening\n",
            "guidelines prevention early detection cervical cancer j low genit ract dis\n",
            "201216175–204 20 oyer va us preventive services task force screening cervical\n",
            "cancer us preventive services task force recommendation statement ann intern med\n",
            "2012156880–91 w312morbidity mortality weekly reportmmwr march 27 2015 v ol 64 11\n",
            "305these revised recommendations advisory committee immunization practices\n",
            "update recommendations published mmwr 1994 1 include updated information two\n",
            "currently available vaccines vaccine safety\n",
            "\n",
            "Index: 113\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "mographic information gathered affected patient table specimens sent nebraska\n",
            "public health laboratory nphl initially cdc cdc multiplex realtime pcr testing\n",
            "performed pneumoniae chlamydophila pneumoniae legionella species human nucleic\n",
            "acid control 1after likely etiologic agent identified pneumoniae case definition\n",
            "modified probable case defined acute respiratory illness either fever ≥1004°f\n",
            "≥380°c pneumonia diagnosed radiograph person epidemiologic link ie resident\n",
            "staff member staff family member visitor confirmed case define\n",
            "\n",
            "Index: 125\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "reportduring june–august 2014 41 probable 14 laboratorycon firmed cases\n",
            "pneumoniae associated single longterm care facility seven patients died facility\n",
            "closed new admissions prolonged period delayed recognition outbreak etiologic\n",
            "agent prolonged transmission period delayed effective interventionswhat\n",
            "implications public health practicelongterm care facilities consider pneumoniae\n",
            "respiratory illness outbreaks facilities need alert outbreaks plan prompt\n",
            "diagnostic testing isolation cohorting ill residents screening staff members\n",
            "illness\n",
            "\n",
            "Index: 150\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "confidence interval ≥cin2 cervical intraepithelial neoplasia grade 2 3\n",
            "adenocarcinoma situ vain23 vaginal intraepithelial neoplasia grade 2 3 vin23\n",
            "vulvar intraepithelial neoplasia grade 2 3sources package insert available\n",
            "httpwwwfdagovdownloadsbiologicsbloodvaccinesvaccinesapprovedproductsucm426457pdf\n",
            "joura ea giuliano ar iversen oe et al 9valent hpv vaccine infection\n",
            "intraepithelial neoplasia women n engl j med 2015372711–23 f emales received 3\n",
            "vaccinations within 1 year enrollment major deviations study protocol naïve\n",
            "polymerase chain reaction pcr negative seronegative\n",
            "\n",
            "Index: 91\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "measured among reported physically active result reinforces importance smoking\n",
            "cessation copd patients health care providers play critical role motivating\n",
            "assisting patients including copd smoking cessation information health care\n",
            "providers helping patients quit smoking available online¶ quitting resources\n",
            "patients also available physically active associated greater likelihood activity\n",
            "limitation measures among persons copd association might indicate copd affects\n",
            "patients’ ability physically active physically active might also reinfor\n",
            "\n",
            "Index: 152\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "830antihpv 16 4032 100 3131 4062 100 3157antihpv 18 4539 998 805 4541 997\n",
            "679abbreviations clia competitive luminex immunoassay mmu millimerck unitssource\n",
            "joura ea giuliano ar iversen oe et al 9valent hpv vaccine infection\n",
            "intraepithelial neoplasia women supplementary appendix n engl j med\n",
            "2015372711–23 noninferiority criterion gmts met four hpv types p0001† f emales\n",
            "received 3 vaccinations within 1 year enrollment major deviations study protocol\n",
            "naïve polymerase chain reaction pcr negative seronegative relevant hpv types\n",
            "dose 1 remaine\n",
            "\n",
            "Index: 81\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "quipment 187 versus 49 unable work 204 versus 48 statespecific prevalence copd\n",
            "ranged 36 puerto rico 40 minnesota south dakota 9 west virginia 94 alabama 96\n",
            "kentucky 103 copd prevalence highest states along ohio lower mississippi rivers\n",
            "figure 1more one third 380 adults copd current smokers activity limitations\n",
            "common among adults copd adults reported copd likely report unable work 243\n",
            "versus 53 adults without copd activity limitation health problems 496 versus 169\n",
            "difficulty walking\n",
            "\n",
            "Index: 108\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "pharyngeal op swabs autopsy specimens patients realtime polymerase chain\n",
            "reaction pcr testing cdc facility closed new admissions 1 month last case\n",
            "droplet precautions implemented ill residents isolated group activities canceled\n",
            "outbreak total 55 persons expe rienced illnesses met case definition 12 hospital\n",
            "ized seven died pcr detected mycoplasma pneumoniae dna 40 specimens pneumoniae\n",
            "consid ered possible cause respiratory illness outbreaks longterm care\n",
            "facilities morbidity mortality respiratory disease outbreaks longterm care\n",
            "facilities\n",
            "\n",
            "Index: 99\n",
            "Article Title: Employment and Activity Limitations Among Adults with Chronic Obstructive Pulmonary Disease \n",
            "\n",
            "Passage:\n",
            "ed guide help states develop implement tobacco control programs§§ cdc also\n",
            "compiled guide communitybased strategies increase physical activity cdc guide\n",
            "strategies increase physical activity community¶¶ 1division population health\n",
            "national center chronic disease prevention health promotion cdc corresponding\n",
            "author anne g wheaton awheatoncdcgov 7704885362references 1 h eron deaths\n",
            "leading causes 2010 natl vital stat rep 2013 621–96 2 us b urden disease\n",
            "collaborators state us health 19902010 burden diseases injuries risk factors\n",
            "jama 2013310591–608 3 lee pn f ry js systematic review\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "# for passage in retrieved_passages:\n",
        "#     # Concatenate the question and passage\n",
        "input_text = f\"question: {question} context: {retrieved_passages}\"\n",
        "\n",
        "    # Encode the input text\n",
        "input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the answer\n",
        "output = t5_model.generate(input_ids, num_beams = 10, max_length=50)\n",
        "\n",
        "    # Decode and store the answer\n",
        "answer = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "answers.append(answer)\n",
        "\n",
        "# Print the generated answers\n",
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ3DD1Qyr8Rf",
        "outputId": "55fbc6dd-ddc1-4acf-8966-390dd10dd589"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: 1994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate answers from each passage\n",
        "answers = []\n",
        "for passage in retrieved_passages:\n",
        "    # Concatenate the question and passage\n",
        "    input_text = f\"question: {question} context: {passage}\"\n",
        "\n",
        "    # Encode the input text\n",
        "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the answer\n",
        "    output = t5_model.generate(input_ids, num_beams = 5, max_length=50)\n",
        "\n",
        "    # Decode and store the answer\n",
        "    answer = t5_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    answers.append(answer)\n",
        "\n",
        "# Print the generated answers\n",
        "for i, answer in enumerate(answers):\n",
        "    print(f\"Answer {i+1}: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-jq_djIr_W7",
        "outputId": "8d8a80f7-3566-4491-b9c4-754514cb4bbf"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: march 27 2015\n",
            "Answer 2: march 27 2015\n",
            "Answer 3: 1after likely etiologic agent identified pneumoniae case definition modified probable case\n",
            "Answer 4: 2014\n",
            "Answer 5: 2015372711–23 f emales received 3 vaccinations within 1 year enrollment major deviations study protocol nave polymerase chain reaction pcr negative seronegative\n",
            "Answer 6: measured among reported physically active result reinforces importance smoking cessation\n",
            "Answer 7: 18 4539 998 805 4541 997 679\n",
            "Answer 8: west virginia 94 alabama 96 kentucky 103 copd prevalence highest states along ohio lower mississippi rivers\n",
            "Answer 9: 1 month\n",
            "Answer 10: 2013 621–96 2 us b urden disease collaborators state us health 19902010 burden diseases risk factors jama 2013310591–608 3 lee pn f ry js systematic review\n"
          ]
        }
      ]
    }
  ]
}